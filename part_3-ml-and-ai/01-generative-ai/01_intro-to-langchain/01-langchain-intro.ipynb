{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "An LLM in isolation knows only what it has been trained on, which doesn't include your personal data, proprietary data, or public articles that were written after the LLM was trained.\n",
    "\n",
    "However, using certain techniques, it is possible to have a conversation with your own documents and an LLM.\n",
    "\n",
    "This notebook illustrates these techniques using the [LangChain](https://www.langchain.com/) framework.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| LangChain API changes a lot, sometimes with non-backwards compatible changes. This guide has been updated to conform to `0.1.11` version. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "\n",
    "[LangChain](https://www.langchain.com/) is an OSS development framework for building LLM applications using Python or TypeScript.\n",
    "\n",
    "It's focused on composition and modularity. It also provides support for common use cases so that you can apply certain techniques in a very easy way.\n",
    "\n",
    "LangChain main components include:\n",
    "\n",
    "| LangChain Component | Capabilities |\n",
    "| :------------------ | :----------- |\n",
    "| **Prompts** | Templates and implementations. |\n",
    "| **Models**  | Integration with LLMs, chat models, etc. |\n",
    "| **Indexes** | Document loaders, text splitters, integration with vector stores, and retrievers. |\n",
    "| **Chains** | Chaining LLMs for complex applications. |\n",
    "| **Agents** | Reasoning engine to determine which actions should be taken. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up shop\n",
    "\n",
    "The Jupyter notebook uses Poetry for the dependency management. \n",
    "\n",
    "The `pyproject.toml` has been set up for you, so you just need to run:\n",
    "\n",
    "```bash\n",
    "poetry install\n",
    "```\n",
    "\n",
    "This will create a virtual environment and install all the required dependencies to run the notebook cells.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| The project has been configured with `package-mode = false` which tells Poetry that `pyproject.toml` is used only for dependency management. |\n",
    "\n",
    "Once installed, you will need to select the newly created virtual environment created by Poetry as your kernel in VSCode.\n",
    "\n",
    "![VSCode Poetry: Kernel configuration](pics/vscode-poetry-configuration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval augmented generation\n",
    "\n",
    "In the technique known as Retrieval Augmented Generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
    "\n",
    "This is useful when you want to ask questions about specific documents (e.g., your PDFs, a set of videos, etc.).\n",
    "\n",
    "The following diagram depicts the different steps involved in this technique.\n",
    "\n",
    "![RAG stages (High Level)](pics/rag_stages_hl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by setting up the environment so that we can interact with the LLM.\n",
    "\n",
    "We will be consuming OpenAI capabilities through Azure OpenAI service.\n",
    "\n",
    "For starters, we will need to identify:\n",
    "\n",
    "+ `openai.api_type` &mdash; identifies the API type between the native OpenAI one (`\"openai\"`) or the Azure OpenAI one (`\"azure\"`).\n",
    "\n",
    "+ `openai.api_version` &mdash; the API spec to use when interacting with the service. The allowed values are documented in [Azure OpenAI reference](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)\n",
    "\n",
    "+ `openai.api_base` &mdash; the endpoint in which OpenAI is accepting requests. You can find this value in Azure Portal (see below).\n",
    "\n",
    "+ `openai.api_key` &mdash; the corresponding API key for the endpoint. You can find this value in Azure Portal (see below).\n",
    "\n",
    "![Azure Portal: endpoints](pics/azure-openai-endpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order not to expose the keys in the source code and to foster a more flexible configuration, we will be using [`python-dotenv`](https://pypi.org/project/python-dotenv/).\n",
    "\n",
    "This module will let you use a `.env` file in which you will be able to configure all the needed pieces of data to connect to Azure OpenAI:\n",
    "\n",
    "```INI\n",
    "AZURE_OPENAI_ENDPOINT = https://....openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY = ...\n",
    "```\n",
    "\n",
    "Along with some other application specific configuration parameters:\n",
    "\n",
    "```INI\n",
    "OPENAI_API_VERSION = 2023-05-15\n",
    "AZURE_OPENAI_TEXT_EMBEDDING_DEPLOYMENT_NAME = ada\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Document Loading\n",
    "\n",
    "![RAG: step 1](pics/rag_step_1.png)\n",
    "\n",
    "The first step of the RAG approach is the loading of documents.\n",
    "\n",
    "The sources can be of many different types according to:\n",
    "\n",
    "+ How we access them:\n",
    "    + Local or remote file systems\n",
    "    + Web sites\n",
    "    + Databases\n",
    "    + Video sites (such as YouTube)\n",
    "    + ...\n",
    "\n",
    "+ The data types of the obtained information:\n",
    "    + PDF\n",
    "    + HTML\n",
    "    + JSON\n",
    "    + Word, PowerPoint, etc.\n",
    "    + ...\n",
    "\n",
    "\n",
    "When performing this step with LangChain, a list of `Document` objects will be returned, with each object having both `page_contents` and `metadata` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a PDF\n",
    "\n",
    "The following snippet illustrates how to load a specific PDF containing a transcript from a Machine Learning training course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF will be loaded as a list of `Document` objects, with each `Document` representing a page of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents and number of pages will be the same\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each object will feature the extracted text in the `page_content` attribute and the contextual metadata information in the `metadata` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "print(page.page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on working with PDFs see [PDF](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf) section on LangChain documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a YouTube video\n",
    "\n",
    "The following snippet illustrates how to download a YouTube video, transcribe it, and then load it into a list of `Document` objects.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| This example does not work with AzureOpenAI. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers.audio import OpenAIWhisperParser\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_path = \"data/youtube\"\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_path),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading information from a URL\n",
    "\n",
    "LangChain also provides loaders for websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsemver/semver.md at mast'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/semver/semver/blob/master/semver.md?plain=1\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Splitting\n",
    "\n",
    "![RAG: Step 2](pics/rag_step_2.png)\n",
    "\n",
    "In this second step, you need to split each `Document` object into smaller chunks in such a way that meaningful relationships are retained.\n",
    "\n",
    "For example, if we have a document with the content:\n",
    "> ...on this model. The Toyota Camri has a head-snapping 80 HP and an eight speed automatic transmission that will...\n",
    "\n",
    "That is split into the following chunks\n",
    "\n",
    "| Chunk # | Content |\n",
    "| :------ | :------ |\n",
    "| 1 | on this model. The Toyota Camri has a head-snapping |\n",
    "| 2 | 80 HP and an eight speed automatic transmission that will |\n",
    "\n",
    "If we're asked: \"What are the specifications on the Camry?\", we won't have the answer on either chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet illustrates how a LangChain splitter is invoked:\n",
    "\n",
    "```python\n",
    "langchain.text_splitter.CharacterTextSplitter(\n",
    "  separator=\"\\n\\n\",\n",
    "  chunk_size=4000,\n",
    "  chunk_overlap=200,  # overlap window\n",
    "  length_function=<built-in len function>\n",
    ")\n",
    "```\n",
    "\n",
    "And the following picture illustrate those concepts:\n",
    "\n",
    "![Chunks](pics/chunks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Get the methods used.\n",
    "\n",
    "There are a few key methods exposed on the splitter object:\n",
    "+ `create_documents()` &mdash; create documents from a list of texts.\n",
    "+ `split_documents()` &mdash;\n",
    "+ `split_text()` &mdash;\n",
    "\n",
    "And there are different types of splitters, all defined in the `langchain.text_splitter` module:\n",
    "\n",
    "| Splitter | Description |\n",
    "| :------- | :---------- |\n",
    "| `CharacterTextSplitter` | Split text by characters. |\n",
    "| `MarkdownHeaderTextSplitter` | Split a markdown file based on its headers. |\n",
    "| `TokenTextSplitter` | Split text looking at its tokens. |\n",
    "| `SentenceTransformersTokenTextSplitter`| Split text to tokens using a sentence tokenizer model. |\n",
    "| `RecursiveCharacterTextSplitter` | Split text by looking at characters and recursively tries to split by different characters to find a way to split it that works. |\n",
    "| `Language` | Split programming languages text. |\n",
    "| `NLTKTextSplitter` | Split text by looking at sentences using [NLTK](https://www.nltk.org/). |\n",
    "| `SpacyTextSplitter` | Split text by looking at sentences using [spaCy](https://github.com/explosion/spaCy). |\n",
    "\n",
    "\n",
    "Splitters take care of maintaining consistent metadata across chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop our intuition about how the splitters work by using two of the most common text splitters: `CharacterTextSplitter` and `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we set a very small chunk size and chunk overlap to see how the splitters behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the splitters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define some sample strings and see how the splitters behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "r_splitter.split_text(text1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the string is not split, because the chunk size was set to 26, and the whole text fits in a single chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try now with a slightly longer string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"abcdefghijklmnopqrstuvwxyzabcdefg\"\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now two chunks are created:\n",
    "+ First chunk is 26 chars long and ends in \"z\".\n",
    "+ Second chunk is 11 chars long, it begins with \"wxyz\" because we told the text splitter to use a chunk overlap of 4. It ends with the last chars of the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use a longer string in which characters are separated by spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we get three chunks:\n",
    "+ first chunk is 25 chars long. Note that the chunk ends in \"m\" (i.e., the last space is dropped).\n",
    "+ second chunk is is also 25 chars long. It starts with \"l m \" because of the specified chunk overlap.\n",
    "+ third chunk is 7 characters long, and it also starts with the last two characters from the previous chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those first set of tests we've used the `RecursiveCharacterTextSplitter` which is the recommended way to start splitting text.\n",
    "\n",
    "Alternatively, we can use the `CharacterTextSplitter`, which splits text based on a user defined character (separator). Let's see how it works with the same examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "c_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The character splitter behaves in the same way as the recursive character splitter because the input text fits in one chunk.\n",
    "\n",
    "For the second test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyzabcdefg']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"abcdefghijklmnopqrstuvwxyzabcdefg\"\n",
    "c_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that despite having set the chunk size to 26, the character text splitter returns a single chunk of 33 characters.\n",
    "\n",
    "It doesn't perform any splitting, because by default, the separator for the `CharacterTextSplitter` is set to a newline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we test it against the third string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the string remains in one chunk because the splitter doesn't find the separator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the definition of the `CharacterTextSplitter` so that it uses `\" \"` as the separator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=\" \"\n",
    ")\n",
    "\n",
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get three chunks as the `RecursiveCharacterTextSplitter` does.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| The behavior of the `RecursiveCharacterTextSplitter` differs from the `CharacterTextSplitter` in that when it cannot split text based on the configured separator it will use `[\"\\n\\n\", \"\\n\", \" \", \"\"]`, which means it'll try to split by `\"\\n\\n\"`, then by `\"\\n\"`, then by `\" \"`, and lastly character by character (empty string). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use more \"real-world\" examples starting with a long text paragraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(some_text)=496 characters\n"
     ]
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "\n",
    "print(f\"{len(some_text)=} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the text contains two long paragraphs separated by `\"\\n\\n\"`.\n",
    "\n",
    "Let's configure the splitters to use `\" \"` as the separator for the character text splitter and `[\"\\n\\n\", \"\\n\", \" \", \"\"]` for the recursive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator=\" \"\n",
    ")\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reviewing the result of splitting with the regular text splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that it creates two chunks, but with no meaningful separation between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, the recursive splitter does a much better job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that chunks are created by splitting the text into paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use a smaller chunk size on the recursive splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is better than the character splitter, but we see that some of the sentences have been split in half.\n",
    "\n",
    "Let's also include the `\".\"` as separator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n",
       " '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns',\n",
       " '. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space',\n",
       " '.and words are separated by space.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's better, but not optimal yet, as we see that `\".\"` are placed at the beginning of the chunks.\n",
    "\n",
    "Let's now use a more contrived sentence separator using a regular expression. Note that we will need to inform the `RecursiveCharacterTextSplitter` that we have started to use regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n",
       " 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n",
       " 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n",
       " 'Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "    is_separator_regex=True\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have much better chunks, without sentences split by half, and with each chunk starting with a proper sentence.\n",
    "\n",
    "In summary:\n",
    "+ `RecursiveCharacterTextSplitter` seems to do a much better job than the `CharacterTextSplitter`.\n",
    "+ We might need to work on a good separator strategy for our text so that:\n",
    "  + Paragraphs are not split in half.\n",
    "  + Sentences are not split in half.\n",
    "  + Chunks start and end in proper sentences, so that they are meaningful on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using splitters with real-world documents\n",
    "\n",
    "Now that we have some intuition about how splitters work, we can start using them on real-world documents.\n",
    "\n",
    "Let's start by loading a PDF and using the `CharacterTextSplitter` with some basic configuration and a `\"\\n\"` separator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separator=\"\\n\",\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because now we're dealing with the `list[Document]` returned by `load()`, we'll need to use `split_documents()` on the splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split_documents()` also returns a `list[Document]`. Each of the resulting `Document` object will contain a small portion of each of the original pages returned by `load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in the PDF: len(pages)=22\n",
      "Number of 'Document' objects after splitting: len(docs)=77\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages in the PDF: {len(pages)=}\")\n",
    "print(f\"Number of 'Document' objects after splitting: {len(docs)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can inspect the contents of each resulting `Document` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters of the first Document: MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machi\n",
      "First 100 characters of the first Document: related to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \n",
      "works in mac\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 100 characters of the first Document: {docs[0].page_content[0:100]}\")\n",
    "print(f\"First 100 characters of the second Document: {docs[1].page_content[0:100]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata of the first Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 0}\n",
      "Metadata of the second Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 0}\n",
      "Metadata of the tenth Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata of the first Document: {docs[0].metadata}\")\n",
    "print(f\"Metadata of the second Document: {docs[1].metadata}\")\n",
    "print(f\"Metadata of the tenth Document: {docs[9].metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how we can link back to our original PDF by having a look the `page` property of the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting by Tokens\n",
    "\n",
    "You can split text and documents by tokens instead of by characters.\n",
    "\n",
    "Splitting by tokens is useful because most of the LLMs have context windows whose size is designated by token counts, and therefore, these splitters will give us a better idea about how the LLMs will see those texts.\n",
    "\n",
    "To get some intuition about how splitting by tokens work, let's initialize a `TokenTextSplitter` with `chunk_size = 1` and a `chunk_overlap = 0`. That will ensure the text we pass will be split into tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "token_text_splitter = TokenTextSplitter(\n",
    "    chunk_size=1,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "text1 = \"foo bar bazzyfoo\"\n",
    "token_text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how those three words end up creating a list of six tokens.\n",
    "\n",
    "Let's now try with a general sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " ' quick',\n",
       " ' brown',\n",
       " ' fox',\n",
       " ' jumps',\n",
       " ' over',\n",
       " ' the',\n",
       " ' lazy',\n",
       " ' dog',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "token_text_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second example, the `token_text_splitter` simply returns a list of the words, some of them prefixed by space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply it in a similar way to our PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "token_text_splitter = TokenTextSplitter(\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "docs = token_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the information in each chunk, and have a look at its metadata too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the first Document/Chunk: MachineLearning-Lecture01  \n",
      "\n",
      "Contents of the second Document/Chunk: Instructor (Andrew Ng):  Okay. Good\n"
     ]
    }
   ],
   "source": [
    "print(f\"Contents of the first Document/Chunk: {docs[0].page_content}\")\n",
    "print(f\"Contents of the second Document/Chunk: {docs[1].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata of the first Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 0}\n",
      "Metadata of the second Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 0}\n",
      "Metadata of the tenth Document: {'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metadata of the first Document/Chunk: {docs[0].metadata}\")\n",
    "print(f\"Metadata of the second Document/Chunk: {docs[1].metadata}\")\n",
    "print(f\"Metadata of the tenth Document/Chunk: {docs[80].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-aware splitting\n",
    "\n",
    "The metadata information of the Document/Chunk is a key concept you can bank on to get additional answers.\n",
    "\n",
    "There are special splitters that enrich that metadata field for us.\n",
    "\n",
    "For example, the `MarkdownHeaderTextSplitter` will split a markdown document by headers and populate the metadata field of the document accordingly to get additional context information.\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_text = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\nHi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \\\n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_text_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    ")\n",
    "\n",
    "md_header_splits = markdown_text_splitter.split_text(markdown_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first document. We'll see that the metadata information of the split is enriched in a way that let us link back to the original document, thus providing additional context for our searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be understood as follows:\n",
    "> The content from the 1st split comes from \"# Title\" &raquo; \"## Chapter 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for the second split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the content comes from \"# Title\" &raquo; \"## Chapter 1\" &raquo; \"### Section\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the third split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Molly', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text comes from \"# Title\" &raquo; \"## Chapter 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we've done a quick walkthrough of how we can split a text document in semantically relevant chunks with appropriate metadata. This will lead us to proper storage of this information in a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Storage\n",
    "\n",
    "![Step 3: Storage](pics/rag_step_3.png)\n",
    "\n",
    "In this step we deal with storage, and we learn about *embeddings* and *vector stores*.\n",
    "\n",
    "In the previous steps we've extracted data from our information sources with the document loaders, and created chunks with the splitters.\n",
    "\n",
    "After splitting, we need to store that information in a convenient format for the subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Embedding vectors* (or *embeddings* for short) is a way to represent content/meaning from text data as a numerical vector. Similar content or meaning will have similar vectors in this numeric space.\n",
    "\n",
    "By using embeddings, we will be able to compare pieces of text and find similarities:\n",
    "\n",
    "![Embedding](pics/embedding.png)\n",
    "\n",
    "+ Embedding vector captures content/meaning of some text.\n",
    "+ Text with similar content will have similar vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By way of embedding, we will be able to tell whether certain pieces of text are similar or not:\n",
    "\n",
    "![Embedding similarity](pics/embedding-similarity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once embeddings have been created, we need a specialized database to store them. Because ultimately embeddings are vectors, that database is called a *vector store*.\n",
    "\n",
    "A vector store will let us interrogate the embeddings to find the most similar to a one given. Each embedding vector will be associated to the original split from which the vector was created.\n",
    "\n",
    "The storage process will be as follows:\n",
    "1. Extract text from our data sources.\n",
    "2. Split them in chunks/splits.\n",
    "3. Create embeddings from those chunks.\n",
    "4. Store the resulting embedding vectors on a vector store.\n",
    "\n",
    "And for the bigger picture, if we consider the use case in which a user types a question and expects a response the additional needed steps will be:\n",
    "1. Query the vector store to find the pieces of information (splits) that most closely resemble what the user is asking for.\n",
    "2. Send those splits to the LLM to craft a response to the user.\n",
    "\n",
    "The diagram below illustrates the overall process:\n",
    "\n",
    "![Storage+Retrieval](pics/storage+retrieval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate the storage process with a real-world scenario by loading some information from a few PDFs.\n",
    "\n",
    "Note that to make it even more realistic, we're loading a PDF twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf\"),\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we proceed to do the splitting using the `RecursiveCharacterTextSplitter` with the default delimiters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we end up with 209 splits with their corresponding content and metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "Before creating the embeddings for our real-world scenario, let's develop some intuition about what the embeddings really are and how we create them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything starts by creating an `embeddings` object through the `OpenAIEmbeddings()` function:\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| The corresponding Azure OpenAI keys need to have been available as environment variables. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"AZURE_OPENAI_TEXT_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a few simple sentences and inspect the corresponding embedding vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"I like dogs\"\n",
    "sentence2 = \"I like canines\"\n",
    "sentence3 = \"The weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embeddings.embed_query(sentence1)\n",
    "embedding2 = embeddings.embed_query(sentence2)\n",
    "embedding3 = embeddings.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector: [-0.020944543635958147, 0.002272979871182798, -0.02557025532608112, -0.02327580427813735, -0.03003646125804415, 0.021631651094632342, -0.011472259896331832, -0.0060980889402820265, 0.011944647205492936, -0.020269703558502175, 0.006834276634038958, 0.030944426282130927, -0.001014558853178482, -0.004570499161415018, 0.003105792284146437, 0.011447720477282411, 0.03720202377454068, -0.001618079410480712, 0.00639256383152028, -3.0938100040575346e-05, -0.0076686229353161725, 0.005782141475298907, 0.010079638319220537, -0.03545971291483799, -0.00819008908257612, 0.01130661765359499, 0.010006019130749676, -0.0027300296941920404, -0.02782789864243465, -0.018404694672229775, 0.037422881339953265, -0.0017208389844497749, -0.01807341018675609, -0.02148441458033581, 0.005137977301469254, -0.02721440850958613, 0.0059079072784957625, -0.004680927478460012, -0.001823598558418838, -0.01404891752297304, -0.012539732541223746, 0.022171522039010006, 0.00868088118885494, -0.02425738849069499, -0.0013788184449343066, 0.011846488597972655, 0.00019363272131690663, -0.02073595717705417, -0.024919957461642356, -0.006073549521232605, 0.004754546201269575, -0.008196223704507828, -0.016392447409015656, -0.013055063135229392, -0.007840399799984722, 0.005067425889625544, -0.0027330972379885424, 0.009631790429108856, -0.0015498287146920406, -0.012374090298486904, 0.008012177595975865, 0.0049539302616146965, -0.011079626397573296, 0.01958259609982798, -0.0027607042008344664, -0.005263742639004812, 0.02782789864243465, 0.022969060143035683, 0.006027537528438317, 0.010791286128266749, 0.005165584497145827, -0.018294265889523487, -0.01718998551304133, 0.022331029659815142, 0.01188943281413979, 0.009282101146517455, 0.000745773564394183, -0.0007185499572113284, 0.00847229472995096, -0.012993715053267135, 0.016404718515524257, -0.03730018145073837, -0.008325057284331834, 0.0019048859078890077, 0.011625631963882666, 0.005236135908989537, -0.01672373189448934, 0.007300528855607058, -0.001112717227868116, -0.016932320216038507, 0.009239156930350318, 0.03052725336432297, -0.0013236042864118096, 0.03590142432037277, -0.016748272244861355, -0.005512206003110075, -0.004610376066616301, 0.012699239230706287, -0.003702411042529524, -0.029717447879079067, -0.0007273688836917922, 0.006969244370133374, -0.03239226411324056, -0.0038251090690992287, -0.0038803232276217255, -0.003953942183261938, -0.004966199971139408, -0.013472236984359946, 0.02035559199083645, 0.003358856847531129, 0.006374159500063863, 0.030208239985357887, 0.016895510621803077, -0.05118959135290627, -0.012269796137712318, -0.01355812541669422, 0.006864951140681384, -0.01877278875193889, -0.011190054248956992, 0.0015237554073290432, 0.013644013849028495, 0.005380305577981513, 0.04044124944080666, -0.004297496378260332, 0.00975448845567856, 0.008110335272173553, -0.010472271817979073, -0.0062483936968670065, -0.006785197330278817, 0.012772858419177148, 0.021791158715437478, 0.032711279354850825, 0.0064232383381627066, 0.014846453764353526, -0.023005867874625923, 0.011484530071517842, -0.001335874112351845, 0.018834138696546338, -0.014674676899684977, -0.017840283377480098, -0.007938558407505004, 0.0325394987648919, -0.011631767517136968, -0.031582456765351465, 0.023754327140552756, 0.04738595439189062, 0.02355800992551219, -0.01428204340092644, 0.014294312644789853, 0.0038649859743005123, 0.013263650525455967, -0.01323911017508395, 0.02883402134271912, -0.0006828908956264039, -0.02137398579762952, -0.005981526001305326, -0.009748353833746852, 0.014760565332019252, 0.010785151506335043, 0.005769871765774196, 0.021128589744490108, -0.018785057995802306, -0.0029018067916912376, -0.020527368855504997, 0.011147110032789856, 0.04417126721335146, 0.02640460302434223, 0.011214593668006414, -0.008871062850641204, -0.00028738164731822443, 0.010220740211585363, 0.03830630415102284, -0.02257642571295455, 0.027435266074998712, -0.03384009821905981, 0.007343473071774196, -0.009159403119947751, 0.0006311276365634786, -0.05089511459902283, -0.000815941445951837, -0.00809806602831014, 0.013889409902167905, 0.03251496027716507, 0.014159345374356735, 0.0003355022417785501, 0.0007358043380938621, 0.008374136122430677, -0.01514092865559178, 0.003601185356874036, 0.005641039117272784, 0.0012369489099207476, 0.009067380065681769, 0.0005456225016846116, -0.0066931742760128355, -0.6749369648081497, -0.009134863700898329, 0.021079510906391267, 0.0013519781934145214, 0.029889224743747618, 0.03747195831540692, -0.017275873945375605, 0.0013366409400933084, -0.0014240632607411582, 0.004846569721196853, -0.00806125643407471, 0.011239134018378432, 0.007791320961885877, 0.020196084370031314, 0.022834091009957373, -0.016048893679678558, 0.0030444432708615844, -0.02430646732879383, -0.01638017816515224, -0.00166869236972378, -0.018097950537128107, 0.025091734326310906, 0.004251484385466045, -0.014122535780121305, 0.013705362862313346, -0.00850296877093209, 0.002435554570123138, -0.022245141227480867, -0.003650264427803529, 0.01595073600348087, -0.021754349121202048, 0.006864951140681384, -0.008693150432718354, 0.0019600999499961805, 0.05467421307231166, 0.010515216034146211, 0.004840434633603849, 0.03477260173087342, 0.01722679510727676, 0.03371740205513529, -0.0030674490344280796, -0.006564341161850127, 0.004453936222438317, 0.010208470967721948, -0.041251056788695756, -0.009987614333631961, 0.014576518292164694, 0.0219383970923792, 0.021533493418434656, -0.006846546343563669, -0.018097950537128107, 0.0053189570303579575, -0.002234636621464441, 0.004024493129444351, 0.010447731467607057, -0.003650264427803529, 0.02591381091806341, -0.03226956422402567, 0.016932320216038507, -0.001981572058079749, 0.009159403119947751, -0.008509104324186391, -0.00864407159461951, -0.0009562772672748072, -0.02890764053118998, 0.020613259150484464, -0.021042701312155836, 0.0004961599004690627, 0.00620851725732702, -0.020650066882074703, 0.013901679146031317, 0.014073456942022462, -0.004782153396946148, 0.01165630693618639, -0.001130354964413719, 0.013005984297130548, 0.003503026982184402, -0.012245256718662898, -0.015840307220774577, 0.0017223726399327017, 0.006128763446924453, 0.0008818916585161183, -0.021140858988353523, -0.01244770855563517, 0.0212390185271964, -0.00013650149344075134, -0.007650218138198457, 0.006441643135280422, 0.0006050543292004812, -0.004515285235723169, 0.02116539933872554, 0.038649857880359934, -0.005766804454808342, -0.019337200046688572, -0.0186623599692326, 0.00724531492991521, -0.009711544239511422, 0.012760588243991138, -0.001984639601876251, -0.02557025532608112, 0.007558194618271179, 0.0008358798985524789, 0.0017269738392121305, 0.007294394233675352, 0.009282101146517455, -0.0004628013803161905, -0.011809679003737224, 0.013938488740266748, -0.002501504782687419, -0.019177692425883436, 0.008828118634474066, 0.0032453612195202817, 0.0011004474019280805, -0.0020536571254063858, 0.002719293640150256, -0.019962959423400508, -0.001038331560901765, 0.012662429636470856, 0.01428204340092644, -0.027410725724626692, -0.00714102170046322, 0.0059079072784957625, 0.013165491917935684, -0.011478394518263539, -0.008282113068164697, 0.007576599415388894, -0.030723570579363535, -0.024674561408502948, 0.02141079539186495, -0.02212244320091116, -0.006926300153966237, -0.00930050594363517, 0.014134805955307314, -0.007147156322394927, -0.006033672616031321, 0.011453855099214117, 0.028613165639951726, 0.012883286270560844, 0.01954578650559255, -0.005282147436122527, -0.013926219496403335, 0.012907825689610266, -0.022269681577852883, -0.0003705862116612082, 0.006085819230757315, -0.004825097613113285, -0.00029294138127448243, 0.0004984605001087771, 0.010656317926511037, 0.00588030008281919, -0.00885879360677779, -0.01498142196610924, -0.0036379947182788182, -0.0027361645489543955, 0.005769871765774196, 0.007920153610387289, -0.011736060746588957, 0.002340463739230006, -0.004978470146325416, -0.012969174702895117, 0.004450868911472464, -0.0028695986295658848, -0.004634915485665724, -0.0022162320571773742, -0.005374170956049806, -0.021177668582588953, -0.0020444549596781766, 0.020122467044205644, -0.005009144652967842, -0.029177576934701407, 0.005555150219277213, 0.00203065136183989, -0.006729983404586968, -0.012858746851511421, 0.0007315866108928271, 0.0001333381834880596, -0.007625678719149035, -0.030429095688125282, -0.0068772208502060955, -0.001953965095233825, 0.012588811379322589, 0.01033730361622336, -0.008668611013668932, -0.003199349459556642, 0.03563148977950654, 0.013680823443263926, 0.034036417296745565, 0.04498107456124055, -0.006453912844805133, -0.007294394233675352, 0.007926288232318996, 0.0037269506944095946, -0.0017576483458545567, -0.0024171500058360715, 0.004748411113676571, -0.008073526609260718, 0.01220231250249576, 0.02029424390887419, 0.020932272529449545, 0.010331168994291654, -0.006656364681777405, -0.011263673437427853, 0.0066931742760128355, -0.016576495380192808, 0.017275873945375605, -0.038698938581103966, -0.00105903684124387, -0.010570429494176761, 0.018870946428136578, 0.025766572541121687, -0.0070735375995853635, 0.0064232383381627066, -0.010791286128266749, -0.012736048824941717, 0.012263661515780613, 0.03786459274548805, 0.0025413816878887027, 0.008723825405022078, -0.0046073087556504485, -0.0015950735304988922, 0.002568988650734627, 0.0035950505021116806, 0.00031633070423086484, -0.02471137100273838, -0.004110382027439922, 0.022919979442291648, 0.007680892644840884, 0.023717517546317325, -0.012920095864796274, 0.0009210016195606144, -0.0394351267405222, 0.008214628501625543, 0.002572056194531129, 0.01542313430296662, -0.0021119388277253846, -0.016539685785957377, 0.028760404016893445, -0.01968075377602567, 0.026257364647400507, 0.001838935811740051, 0.0074661710983439005, 0.013190031336985106, 0.008055121812143002, -0.012797397838226568, 0.019533515399083948, 0.02979106706754993, -0.003772962454373234, 0.0034999594383879, -0.0031778773514730737, 5.856910628895567e-05, -0.01566853035610603, -0.014318852995161871, 0.004098111852253914, 0.01750899889200641, 0.0020429210713646014, -0.035754185943431056, 0.005009144652967842, -0.0013028990060697044, 0.030429095688125282, 0.033152990760385616, 0.020085657449970214, 0.005653308826797495, -0.006180910061650447, -0.021263557014923228, 0.016993668298000766, 0.007895614191337866, 0.0001064021439842115, -0.020196084370031314, -0.00506435857865969, -0.007742241658125736, -0.01549675349143748, -0.009036705093378046, 0.008478429351882668, -0.01577895913881232, 0.004088909919356353, 0.0012354151380224963, -0.012374090298486904, 0.02095681287982156, -0.004318968486343901, 0.037643735180075466, -0.005766804454808342, -0.010367978588527085, 0.005128774902910397, 0.03877255776957483, 0.012858746851511421, -0.015877116815010008, -0.02418376930222413, 6.302649262505013e-05, -0.00871155522983607, 0.03798728890941257, -0.00040106898226443746, 0.010006019130749676, 0.001102748001567795, -0.003653331971600031, -0.014748295156833242, 0.008355731325312962, 0.020404670828935295, -0.01803660059252066, -0.00011071573920484492, -0.01687097027143106, 0.02278501217185853, 0.011840353976040947, -0.0227482025776231, -0.009073514687613476, 0.007588869124913605, -0.010766746709217328, -0.018858677184273163, -0.00639256383152028, -0.019619403831418223, -0.007699297441958599, 0.004742276491744864, -0.0033833964994111993, -0.011705385774285234, -0.007963097826554426, -0.020159276638441075, 0.014147075199170727, -0.02046602077354274, -0.002434020914640211, 0.01930039045245314, 0.011257538815496147, -0.007717702239076314, -0.011355696491693835, -0.016576495380192808, -0.0004516818832998434, 0.10571656604827621, 0.007619543631556031, 0.014625597130263538, 0.013263650525455967, 0.02672361640330731, 0.010392518007576505, -0.02630644348549935, -0.008214628501625543, 0.0046625226813422965, 0.007742241658125736, -0.02137398579762952, -0.021705270283103203, 0.014858723939539534, -0.0026456749173406923, 0.019104073237412575, -0.00033128451457751514, -0.002947818551654877, -0.01334953895779024, -0.0017622495451339855, -0.012349549948114887, 0.0028741998288453136, -0.01214709904246521, 0.008392540919548393, 0.029766526717177912, 0.02242918733601283, 0.004926323531599421, 0.0070735375995853635, 0.009091919484731191, -0.0019156219619307921, -0.011509069490567262, -0.01303052371617997, 0.015067310398443513, -0.0038036369610156603, -0.012079614475926054, -0.01522681801924865, -0.0003905246060541879, -0.008410945716666108, 0.03330022913732734, 0.021607112606905517, -0.0036686692249212442, 0.031754233630020015, 0.020760495664780994, 0.00702445876148652, -0.015803497626539147, 0.010963062992935297, -0.02082184560938844, -0.024527323031561226, 0.02782789864243465, -0.00774837674571874, -0.015214547844062641, 0.029913763231474443, 0.00702445876148652, -0.022834091009957373, -0.021214478176824383, -0.0008374136122430678, 0.0010881775759880453, -0.026502760700539914, -0.010183931548672526, -0.021091780150254678, -0.013055063135229392, -0.02775427945396379, -0.03155791827762464, -0.01241089896139974, -0.01845377351032862, 0.002098135229887098, -0.055803035661811023, -0.025018115137840045, 0.0007914018522794285, -0.020085657449970214, -0.005613431921596211, -0.01585257646463799, -0.01628202048895455, -0.017582618080477272, -0.0068281420121072516, 0.019337200046688572, 0.004901783646888702, 0.015202277668876631, -0.008883333025827212, 0.01441701067135956, 0.024956767055877786, -0.0062882706020682905, -0.0025889271033352687, 0.017079556730335038, 0.005009144652967842, -0.012920095864796274, 0.008030581461770986, -0.005233068132362386, 0.00206439317944817, 0.0032054843143189977, 0.003634927174482316, 0.014147075199170727, -0.007791320961885877, 0.018883217534645183, 0.005953918805628753, 0.017803475645889855, 0.011705385774285234, -0.0010467670153038347, 0.02282182176609396, -0.014478359684644412, 0.001920223161210221, 0.030306397661555576, -0.00032438274476220304, -0.02316537549543106, -0.0025306456338469187, 0.02623282429702849, 0.01380352146983363, 0.016674653056390494, 0.0062882706020682905, -0.018147029375226952, 0.002098135229887098, 0.025717493703022842, -0.03553333210330885, 0.03342292530125185, -0.0006491489033951378, 0.011913972233189213, 0.024600942220032087, -0.014502900035016428, 0.010006019130749676, -0.0038281766128957307, -0.010085772941152244, -0.005475396874535942, -0.0066809041008268275, 0.043680475107072646, 0.02662545872710962, -0.01768077761932015, -0.025067193975938887, 0.012969174702895117, -0.009196212714183182, -0.011239134018378432, -0.011791274206619509, -0.004171731040724775, 0.03153337606460743, -0.021705270283103203, -0.015729878438068286, -0.030208239985357887, 0.01473602591296983, 0.012386359542350317, 0.01445382026559499, -0.016097972517777403, -0.005840423177617906, -0.012533596987969443, 0.001035264133520587, -0.005843490488583759, -0.01310414290465083, -0.01634336857091681, -0.03293213319497303, -0.01803660059252066, -0.016466066597486517, -0.0047576135122354285, 0.03251496027716507, -0.02954567101441052, 0.009257561727468033, -0.008736095580208086, 0.006061279346046596, -0.0012622552731269571, -0.02035559199083645, 0.005220798422837675, 0.011447720477282411, 0.016981399054137352, 0.03703024690987213, 0.01677281259523337, -0.0003757625317467345, 0.016846429921059045, 0.0066870391884198315, -0.005981526001305326, -0.012478383527938893, -0.0008182420455915514, -4.014044766772855e-05, -0.008509104324186391, 0.01894456561660744, -0.0033159126313639918, -0.0036134550663987474, 0.030551793714694984, 0.01777893529551784, -0.028858561693091134, 0.005236135908989537, 0.011883298192208085, -0.013496776403409367, -0.014711486493920407, -0.005233068132362386, 0.015815768733047752, 0.0008358798985524789, 0.016883239515294475, 0.010662453479765337, 0.01736176237770988, 0.008410945716666108, 0.018613281131133756, -0.012509057568920023, 0.019337200046688572, -0.011067356222387288, 0.020196084370031314, -0.022699123739524256, -0.009269830971331447, -0.00023887759533142042, -0.004352710303952181, -0.007147156322394927, -0.014183884793406158, 0.0040735724332044915, -0.002650276116620121, 0.01282193725727599, 0.025275780434842868, 0.024281926978421815, -0.01424523380669101, 0.01214709904246521, -0.008723825405022078, 0.020907734041722716, -0.011975321246474066, -0.030380016850026437, 0.014785104751068673, -0.028956719369288824, -0.013680823443263926, -0.03067449174126469, -0.034208194161414116, -0.0230917563069602, 0.005641039117272784, 0.017521269998515016, -0.02384021557288703, 0.020441480423170726, 0.014110266536257892, -0.009153268498016044, -0.003472352475541976, 0.020576449556249033, 0.023435311898942483, 0.0017622495451339855, 0.006613420465610268, 0.028539546451480866, 0.0023312613406711482, -0.03003646125804415, 0.029275734610899093, -0.0030014990546944472, -0.0021104049394118094, 0.0018067275331993737, 0.027631581427394088, -0.0041134493384057755, -0.009981479711700254, 0.01287101702669743, -0.005490733895026506, -0.009515227024470857, -0.02042921117930731, 0.026502760700539914, -0.004874176916873426, 0.019705294126397686, -0.012576541204136581, -0.015791228382675732, -0.010564294872245054, 0.0066870391884198315, -0.021140858988353523, 0.014012107928737609, -0.029521130664038504, 0.004226944966416623, -0.016331099327053396, 0.005233068132362386, -0.021128589744490108, 0.03857623869188907, -0.022944519792663664, 0.012275931690966621, -0.004091977230322207, -0.01739857197194531, 0.0019462964685732183, -0.021791158715437478, 0.002320525286629364, 0.01979118255873196, -0.03131252222448523, -0.01477283550720526, 0.006723848316993964, -0.011926242408375221, -0.0013918550986158052, 0.005150247010993965, -0.002483099985569704, 0.026085587782731956, -0.01922677126398228, -0.0017806542258363763, -0.01999976901763594, 0.006095021629316173, -0.008490699527068676, 0.010926254330022462, -0.007901748813269573, -0.01608570327391399, 0.00206439317944817, -0.011355696491693835, 0.0220488240124403, -0.0021886248615008014, -0.0055827574149537856, -0.002553651397413414, -0.019030454048941714, 0.008637936972687802, -0.02342304079243388, -0.0025858595595387667, -0.0030643817234622265, 8.962703044009244e-05, -0.0005391041748438621, 0.0015482949427937896, -0.008999895499142615, -0.00211807368248774, 0.026527301050911934, -0.009570441415824003, 0.03327568692431013, 0.046993319961809485, -0.034036417296745565, 0.018711440669976633, -0.006318945108710717, 0.007257584639439921, -0.03779097355701719, 0.005736129948165916, 0.0005099634400996869, 3.14653195786836e-05, -0.0008964620258882059, 0.02809783504594608, -0.011091896572759304, -0.0024416894248854935, 0.00984651150994454, 0.01602435519195173, -0.005116505193385685, -0.016171591706248264, 0.0008772904592366894, 0.007950828582691012, 0.03069903022899152, -0.030968966632502943, -0.026380062673970212, 0.021054970556019247, 0.00926369634939974, -0.0026410737180612635, 0.009772893252796275, -0.01725133359500359, 0.0012936967239261712, 0.006061279346046596, 0.019950690179537094, 0.008815848459288058, -0.020453751529679327, -0.02511627281403773, -0.038698938581103966, 0.021324906959530675, -0.01244770855563517, -0.01615932246238485, -0.006165572575498586, -0.012459978730821178, -0.02263777379491681, 0.01396302815931617, 0.005254540240445954, -0.005769871765774196, 0.020024307505362767, 0.029349353799369954, 0.008828118634474066, 0.0006146401416300705, -0.011594957922901538, -0.014613327886400124, -0.001144925389993469, -0.01628202048895455, -0.03244134108869421, -0.017067287486471627, -0.032833975518775343, 0.012858746851511421, 0.022146983551283177, 0.02025743431463876, -0.0006794399961668323, 0.01517773824982721, -0.010527485278009624, -0.004076639744170345, -0.00016851799228648505, 0.007515250402104041, 0.009815837468963412, -0.016920049109529905, -0.0064968575266335675, 0.024956767055877786, -0.0024125488065566427, 0.015607181342821177, -0.01334953895779024, -0.02438008651726469, 0.008883333025827212, -0.021680729932731187, -0.00505208886913498, -0.032833975518775343, -0.01764396802508472, -0.007159426497580936, 0.03133706071221206, -0.00825757271779268, 0.0007595771040248072, 0.007644083050605453, -0.0028818685719212444, 0.007619543631556031, -0.025054924732075476, -0.01404891752297304, -0.006754522823636391, 0.006864951140681384, 0.021533493418434656, -0.0009133329929000078, -0.032981213895717065, 0.009920130698415401, -0.02092000328558613, 0.02267458338915224, 0.0022331029659815142, 0.005260675328038959, -0.0016012085016765723, 0.007239179842322206, -0.019349469290551983, -0.0004052867094654724, -0.03155791827762464, -0.02063779763821129, -0.0015298902620913988, -0.009392528997901153, -0.027901517830905512, 0.023889294410985872, 0.0007898681385888396, -0.01745992005390757, -0.01922677126398228, 0.0012614884453854937, 0.014907802777638379, 0.00448154341811489, 0.007392552375534336, 0.0023021204895116486, 0.013496776403409367, -0.002872666173362387, 0.012650160392607442, -0.027876977480533496, 0.013533585997644797, -0.011220729221260717, -0.010294359400056224, -0.004423261715795891, 2.746325540397745e-05, 0.008055121812143002, -0.029447511475567643, -0.005889502481378047, -0.024907686355133754, 0.02412241935761668, -0.010472271817979073, -0.03025731882345673, -0.01238022492041861, -0.004999942254408985, -0.007233045220390499, 0.031754233630020015, -0.03852716171643542, -0.01860101188727034, 0.005910974589461616, 0.02082184560938844, -0.014183884793406158, 0.00896308683622978, 0.24716277955225666, -0.0232144543335299, 0.010558160250313349, 0.012312741285202052, 0.00466558999230815, 0.01608570327391399, 0.013410887971075093, -0.025226701596744023, 0.009484552983489727, 0.02672361640330731, 0.0004896415736283134, -0.009042839715309753, -0.02031878239660102, 0.006429373425755711, 0.003815906670540371, 0.004990739855850127, -0.01538632470873119, -0.0038036369610156603, -0.01704274713609961, -0.024318736572657245, -0.012662429636470856, 0.0022714459828692226, -0.014220694387641588, -0.0064845873514475585, 0.011159380207975864, 0.02033105350310962, -0.030306397661555576, -0.0013167026039079908, -0.0034232731717818345, 0.010147121954437096, -0.002019915307798106, -0.010122582535387675, 0.01750899889200641, -0.02099362247405699, 0.010693127520746467, -0.014821914345304103, -0.005610364610630358, -0.016134782112012833, 0.005091965774336263, 0.014883263358588956, 0.014650137480635555, -0.006141033156449164, 0.014858723939539534, -0.01669919340676251, 0.005693185731998779, 0.03141067990068292, 0.012772858419177148, -0.013717633037499356, 0.015643990005734014, 0.04250257554211963, -0.02024516507077535, -0.005432452658368805, 0.018478313860700635, 0.025275780434842868, -0.011631767517136968, -0.00843548513571553, 0.021803427959300892, -0.006705443985537547, -0.04103019922328317, 0.004076639744170345, -0.006625690175134979, 0.00812260544735956, -0.009098054106662899, 0.03423273264914094, -0.013374078376839663, 0.003818974214336873, -0.021324906959530675, 0.01976664220835994, 0.005233068132362386, 0.006539801742800704, -0.0011226863377531125, -0.00018222564934559525, -0.004245349763534338, -0.006355754702946147, -0.024502784543834397, -0.005680916022474068, 0.0037821648529320915, 0.036441297127395626, 0.01195691644935635, 0.014895533533774964, -0.012674699811656864, -0.0005762970083270377, -0.009325045362684593, -0.0054416545912663655, -0.025398478461412573, -0.043484159754677267, 0.004803625505029717, 0.004055167636086776, 0.016895510621803077, -0.017656237268948133, -0.009441608767322592, -0.011539743531548392, 0.006190112460209305, -0.010079638319220537, 0.016711462650625925, -0.004647185660851732, 0.010871039938669317, 0.019435357722886258, 0.005920176988020474, 0.02278501217185853, -0.02472364024660179, -0.01672373189448934, 0.024846338273171495, 0.006944704951083952, -0.0023036543778252243, 0.00857658795940295, -0.009711544239511422, -0.010018289305935684, 0.0018143961598599803, -0.00995080473939653, -0.01982799215296739, -0.02620828580930166, -0.0031502703886271497, 0.03060087255279383, 0.006095021629316173, 0.011791274206619509, 0.011705385774285234, -0.015607181342821177, 0.004417126628202887, 0.0022975195230628687, -0.004549027053331449, -0.028024215857475217, 0.010889444735787032, 0.00702445876148652, -0.0005686283816664312, -0.017374031621573294, -0.014269773225740433, 0.013116412148514245, 0.016392447409015656, -0.0404903301415507, 0.022367839254050573, 0.002667147025424261, 0.00030732007081503524, -0.019889340234929647, 0.004714669296068291, 0.024539592275424637, 0.010116446982133372, -0.04080934165787059, -0.0008297449855824612, 0.011742195368520664, 0.013472236984359946, 0.0053189570303579575, -0.014564248116978686, -0.00296315580497609, 0.01214709904246521, -0.03268673714183362, 0.0067483882017046835, 0.00631281048677901, -0.017337222027337864, -0.004184000750249485, -0.020539639962013603, 0.003889525626180583, -0.0014347993147829424, -0.006662499769370409, 0.02655183953863876, -0.011429315680164696, -0.029741986366805896, 0.007564329705864183, -0.004493813127639601, 0.013300459188368802, -0.022846362116465978, -0.004159460865538766, 0.03334930611278099, 0.010257549805820793, -0.023508931087413344, -0.013496776403409367, -0.15420680081664898, 0.020907734041722716, 0.011625631963882666, -3.582684880911625e-05, -0.01922677126398228, 0.01856420229303491, 0.03828176566329601, -0.036269520262727076, 0.013619474429979073, -0.010766746709217328, 0.03138614141295609, -0.0034508803674584074, -0.0343063518376118, -0.019987497911127337, -0.0033404520504134137, -0.011766734787570086, 0.018147029375226952, 0.00885879360677779, 0.02250280652448369, 0.002075129233489954, 0.02476044984083722, -0.021091780150254678, 0.02511627281403773, -0.021435333879591775, 0.019521246155220533, 0.03408549427219922, 0.005104235483860974, -0.0012814268979861358, -0.023263535034273936, -0.005254540240445954, -0.02468683065236636, -0.037741892856273156, 0.029938303581846463, 0.022723664089896272, 0.007687027732433888, 0.005481531496467649, 0.012920095864796274, -0.021545762662298067, -0.011036682181406158, 0.016367908921288827, 0.015643990005734014, 0.036269520262727076, 0.029447511475567643, -0.019140882831648005, 0.0070796726871783676, -0.020159276638441075, 0.01186489339509037, -0.004680927478460012, -0.0009739151202357347, -0.026159206971202817, 0.01570533995034146, 0.0034907570398290426, 0.011496799315381254, 0.0004884912738084562, 0.012993715053267135, 0.009104188728594606, 0.0021012027736836, 0.02883402134271912, -0.02133717620339409, -0.007368012956484915, -0.0069385698634909475, -0.01549675349143748, 0.003717748295850737, -0.007165561119512642, 0.0061993148587681625, -0.029251194260527077, -0.03850262322870859, 0.01525135743829807, -0.022146983551283177, -0.0036379947182788182, -0.01334953895779024, -0.00297542574733145, 0.019484436560985103, -0.009269830971331447, -0.015643990005734014, 0.019104073237412575, -0.02733710653615583, 0.03025731882345673, -0.0015176204361513634, -0.01574214954457689, 0.004613443377582155, 0.03327568692431013, -0.021778889471574064, 0.010570429494176761, -0.012159368286328623, 0.01188943281413979, 0.005766804454808342, -0.012993715053267135, 0.001805193877716447, -0.00892627724199435, 0.005515273779737226, -0.026085587782731956, -0.009233022308418612, -0.013324999538740818, -0.007257584639439921, 0.016097972517777403, 0.02039240158507188, 0.019251311614354297, 0.003634927174482316, -0.009447743389254297, 0.02073595717705417, -0.010674722723628752, -0.017619427674712702, 0.020969082123684975, 0.009662464470089983, 0.024674561408502948, 0.02912849623395737, 0.011122570613740434, 0.004085842142729203, 0.011300483031663283, -0.018196108213325797, 0.0249690362997412, 0.014355661658074706, 0.00516865180811168, 0.008533643743235814, 0.012907825689610266, -0.015815768733047752, -0.014748295156833242, 0.010552024697059046, 0.009766757699541974, 0.050208007140348634, -0.015803497626539147, 5.545373034606315e-05, 0.015766688032303716, -0.0027515018022756087, -0.011275942681291267, -0.08912780328686519, -0.03715294307379665, -0.0084048110947344, 0.015263626682161484, -0.03447812870228035, 0.01722679510727676, 0.004880311538805133, 0.016097972517777403, 0.0023435310501958594, 0.01661330497442824, 0.005079695599150255, -0.009245291552282025, -0.005288282523715532, 0.0016579563156819959, 0.006564341161850127, -0.013140952498886261, -0.006729983404586968, -0.015447673722016041, -0.02078503601515301, 0.021324906959530675, 0.006276000892543579, 0.012772858419177148, 0.005751466968656481, -0.00812260544735956, -0.013509045647272781, -0.0019647011492756094, -0.030551793714694984, 0.016588764624056222, 0.01323911017508395, -0.021067241662527852, 0.015459943897202049, -0.02099362247405699, 0.013128682323700253, -0.018110219780991522, -0.01965621342565365, -0.008447755310901538, 0.005729994860572912, 0.003702411042529524, 0.02782789864243465, -0.0038312439238615843, -0.004420194404830037, 0.014061186766836454, 0.002371138245872432, -0.03008554195878818, 0.003634927174482316, 0.0019278917878708275, -0.006705443985537547, 0.01683416067719563, 0.02880948285499229, -0.010398652629508212, -0.014625597130263538, -0.0249690362997412, -0.060858191376250564, 0.01677281259523337, 0.028122373533672907, -0.0057391972591317696, 0.01975437296449653, 0.03077264941746238, -0.019975228667263922, 0.0020889328313282406, -0.015300436276396915, 0.008785174418306929, -0.0059631212041876104, 0.031189822335270338, 0.018760519508075477, -0.0005141811673007219, -0.028858561693091134, 5.52140857629192e-05, 0.0038925929371464367, -0.015484483316251471, -0.0035459711983515394, 0.025545716838354295, -0.02564387451455198, -0.005834288090024902, -0.01542313430296662, -0.008521373568049806, -0.022551885362582534, -0.03835538485176687, 0.003708546130122528, -0.02082184560938844, -0.019067263643177144, -0.010042828724985107, -0.008533643743235814, -0.019067263643177144, 0.014502900035016428, 0.028858561693091134, -0.007300528855607058, 0.024073340519517837, -0.009122593525712321, -0.001420229005618517, 0.007588869124913605, 0.021177668582588953, 0.010852635141551601, -0.018122489024854936, -0.00788947956940616, 0.0016840296230449933, -0.01538632470873119, -0.0036379947182788182, 0.017337222027337864, -0.0027330972379885424, -0.015447673722016041, -0.016527416542093963, -0.0367603123690059, 0.02979106706754993, -0.008055121812143002, -0.005726927549607058, 0.0319750911954326, -0.032097787359357116, 0.003524499090267971, -0.019361738534415397, -0.0009041306525488124, -0.005889502481378047, 0.009245291552282025, -0.00219322606078023, -0.0018297334131811933, 0.0077974555838175846, -0.012091884651112064, -0.025447557299511415, 0.03452720940302438, -0.02182796830967291, 0.007803590671410589, 0.008036717015025287, -0.0045275549452478804, 0.03050271487659614, 1.8009281510219927e-05, 0.024073340519517837, 0.002121140993453594, 0.013018254472316557, -0.02235557001018716, 0.019361738534415397, -0.035140697673227715, -0.001106582256690436, -0.012245256718662898, -0.03938604603977816, 0.0003109626481061416, 0.022036554768576886, -0.0178525544839887, -0.036220439561983044, 0.0029646896932896656, 0.031018045470601788, -0.008079661231192425, -0.01396302815931617, -0.005368035868456801, -0.03823268496255198, 0.009680869267207699, -0.01732495278347445, -0.003950874406634787, -0.02679723559177817, -0.03504253999703003, -0.00771156715148331, 0.004297496378260332, 0.0005195491943216141, 0.000174844597639953, 0.02133717620339409, -0.021570303012670086, -0.02011019593769704, -0.014232963631505002, -0.006840411721631963, 0.009177807917065467, 0.010772881331149033, 0.0018312671850794443, 0.017938442916322975, 0.021815699065809494, -0.008834253256405774, 0.01262562097355802, -0.011521338734430677, 0.0016257480371413184, 0.02471137100273838, -0.007441631679294478, -0.0006173241551405166, 0.0062269215887834385, -0.036637612479791005, -0.021778889471574064, -0.0046686577689353005, 0.013950758915452756, 0.010061233522102822, 0.01628202048895455, 0.00520239362571996, -0.0010544356419644413, -0.003947807095668933, -0.019374009640924002, 0.014073456942022462, 0.04149645284183516, -0.0032484287633167837, 0.00415332624360706, 0.008392540919548393, 0.019202230913610265, 0.018478313860700635, -0.012509057568920023, -0.011417045504978686, 0.0037944345624568027, 0.012711509405892295, -0.028024215857475217, -0.0008596526062757619, 0.008147144866408983, 0.018122489024854936, -0.002572056194531129, 0.007496845604986326, -0.018674631075741202, -0.03069903022899152, 0.011208459046074707, 0.013742172456548777, -0.002938616385926668, -0.013987568509688186, -0.031656075953822325, -0.0005287515346728095, -0.010754476534031318, 0.0036441295730411734, -0.016048893679678558, -0.011030547559474453, 0.00034700518176945995, 0.01638017816515224, 0.03860078090490628, -0.00027434499363672573, 0.03050271487659614, 0.010668588101697045, -0.006239191763969447, 0.01672373189448934, -0.0035582409078762506, -0.01334953895779024, -0.035214316861698576, 0.02839230993718433, 0.0017913902798781605, 0.0014148608621823006, 0.021668460688867772, -0.013423157214938506, -0.008116470825427855, 0.01791390256595096, 0.000991552973196662, -0.032711279354850825, 0.00922688675516431, 0.015275896857347492, -0.013889409902167905, -0.025668414864923998, -0.030011922770317324, 0.004800557728402566, -0.002591994647131771, -0.003579713248790468, -0.0004524487401451379, 0.023263535034273936, -0.015607181342821177, 0.029496590313666485, -0.007975368001740434, -0.01065018330457933, -0.012858746851511421, 0.03276035633030448, 0.009429338592136582, 0.024429165355363536, 0.029153036584329387, -0.01522681801924865, -0.003840446322420442, 0.004984604768257123, -0.0009394063002630052, 0.0004808226471478497, -0.012429303758517455, -0.014650137480635555, -0.01915315207551142, -0.025373939973685745, -0.006644094972252694, 0.006183977372616301, -0.02525124194711604, 0.007975368001740434, 0.021631651094632342, 0.019312659696316552, -0.003576645704993966, -0.0029248127880883816, -0.016012084085443128, 0.009515227024470857, -0.003671736535887098, -0.013140952498886261, -0.016539685785957377, 0.013778981119461613, -0.008312787109145826, -0.035165236160954544, -0.004101179628881064, 0.010153256576368803, 0.012282066312898328, 0.002099668885370025, -0.012312741285202052, -0.00122774651136189, 0.018429235022601794, -0.022515077630992295, 0.0023312613406711482, -0.012613350798372011, -0.002644141261857766, 0.024465974949598967, 0.009061244512427468, -0.002845058977685814, 0.013251380350269957, -0.015337245870632345]\n",
      "Embedding vector: [-0.012135879910277793, 0.0038950704192923236, -0.012992151909804763, -0.019983963452197245, -0.024979956177891824, 0.022894000231386144, -0.002940617223537172, 0.0029196931979193906, 0.0011210399230343335, -0.017627607292139837, 0.007860960008656954, 0.02910036034130791, 0.0038532226008874196, -0.010210878866668245, -0.000787464137098088, 0.012728188998299153, 0.03571875993624866, -0.0008844385138156156, 0.015631786612796666, 0.0003253268867440307, -0.01802677217306658, 0.0009061672021891615, 0.01078387232326072, -0.03736692160161509, -0.0056719951222191645, 0.007777264371847146, 0.005527137199728857, -0.011543571753579064, -0.0227909903601314, -0.018516070458510562, 0.03868030258238756, 0.0038210318997049827, -0.020009716385672248, -0.026422096238103505, 0.0075583681626001575, -0.03260270341455027, 0.013198172583636885, -0.006225674344366704, 0.002966369691350858, -0.014073758351947473, -0.0036053543414810525, 0.018477441058298058, 0.0054917273818620455, -0.020563397004803738, 0.004558197978894017, 0.015129611860615183, 0.0005971368317252903, -0.0023644041845990046, -0.026808384652292745, -0.013172419650161882, 0.0031595136656148194, -0.005591518136432414, -0.015528776741541923, -0.009637884478753137, 0.0013206220142517164, 0.00686948790235412, -0.00967007564559689, 0.009991981726098623, 0.0024303951453060655, -0.011054274399457715, 0.012000679803501928, 0.00985678161932276, -0.011672334558308812, 0.006341560682358949, 0.004091433510240661, -0.014563056637391457, 0.03031072958818037, 0.027529455613721217, -0.00013127755046450485, 0.002575253067796372, 0.00042612390631658947, -0.02992444117399113, -0.015786302351001417, 0.02418162641603834, 0.01604382609781564, -0.002514090782115874, -0.0009665247086985656, -0.008253686656214945, -0.00483181870611407, -0.0003615413964704396, 0.022675104022139153, -0.04182211203756095, -0.013919243545065359, 0.006518609306031692, 0.013442821726358876, -0.002671825171343682, -0.004892980991794567, -0.001149206728361301, -0.00557864213535623, -0.008665727072556554, 0.005858701095945033, 0.025263232858181054, -0.014987973520470568, 0.032216416863006296, -0.021670754517776183, -0.006966059540240113, -0.004886542758425817, 0.007577682397045093, -0.000509417240852348, -0.023254535712100382, 0.004506693043266645, 0.015193993262980056, -0.03275722101540029, -0.007790140838584647, 0.010017734659573625, -0.009142148891263037, -0.012123004374862925, -0.004954143277475066, 0.023203029845150373, -0.004188005613787971, -0.0018976395995303193, 0.02794149696138546, 0.01803964863980408, -0.053771286905435506, -0.01704817560217861, -0.020241489061656737, 0.008536964267826807, -0.005230983121379494, -0.006563676473951631, -0.0018960301576034608, 0.013520078664138617, 0.01311447648116576, 0.04071475079929797, -0.0079768463466492, 0.012380529052999785, 0.024580791296965082, -0.014550180170653956, -0.008227933722739942, 0.0011170160271788644, 0.010841815492256842, 0.028945844603103163, 0.019005368743954545, 0.011723839493936183, 0.01872209020102005, -0.019237141419939038, 0.014060881885209972, -0.004506693043266645, 0.02258497061762191, -0.008762298710442547, -0.013532955130876118, -0.004931609926345755, 0.039761907161885005, -0.016069579031290644, -0.02910036034130791, 0.01270243606482415, 0.037469933335515106, 0.025894170415092285, -0.004751342185988636, 0.014627438039756331, -0.004683741666939388, 0.01503947845609794, -0.009979106190683755, 0.021748013318201195, -0.007069069877156174, -0.0039884231733246, -0.003750212263971359, -0.014331283961406966, 0.016108208431503148, 0.0018493536641719934, 0.001339131585940887, 0.003888632185923573, -0.025520758467640545, -0.008260123958261062, -0.013532955130876118, 0.01979082017642526, 0.03355554705196324, 0.02240470194594216, 0.009367483333878776, -0.008678602607971422, -0.004039928574613288, 0.0074811102934977825, 0.03461140242327621, -0.019288645424243776, 0.030259223721230365, -0.029435142888547147, -0.0012602645077423123, -0.005118315434410307, -0.0006321441435912261, -0.03672310944061163, -0.010468403544805105, 0.006843734968879117, 0.015618910146059166, 0.039246855942966015, 0.014472922301551581, -0.002469023847026594, -0.001665866923545829, 0.014099511285422478, -0.010770995856523219, 0.010886882194515465, -0.005945615849439217, 0.003156294548930444, 0.0024223475864257856, 0.008491897565568186, -0.012065061205866801, -0.6823390561215824, -0.013249677519264256, 0.0140093769495826, -0.003082256029343103, 0.03164985977713731, 0.03270571514845028, -0.009567065774342146, -0.0037566504973401095, -0.002287146781157947, -0.0009158243776192938, -0.018232791915576068, 0.022198682203432674, 0.010828939025519341, 0.012625178195721776, 0.010539223180538728, -0.021271591499494712, -0.0042201958493090904, -0.02763246548497596, -0.005617271069907417, -0.009734457047961763, -0.022984133635903386, 0.007139889512889797, -0.012631616429090527, -0.012515730091098281, 0.016932289264186367, -0.015812053421831153, 0.013481450195248747, -0.021078446361077457, -0.0006196702992699301, 0.013919243545065359, -0.03152109883505283, 0.017125432539958352, -0.02170938391798869, -0.007062631643787423, 0.0531017180856665, 0.0032383808602287232, 0.014035129883057603, 0.026756880647988007, 0.006740725097624373, 0.029950194107466133, -0.01913413154868429, 0.003347828964852218, -0.00031868757499783576, 0.008414639696465812, -0.039710405020225534, 0.0056333661876679765, 0.009843905152585257, 0.016056702564553143, 0.01209725144138792, -0.007088384111601109, -0.013661717935605866, 0.00988897185484388, 0.005836167279154406, 0.002749082807615398, 0.012213137779380167, -0.010011296426204875, 0.02693714745702249, -0.036130803146558164, 0.012213137779380167, 0.0070175649415288015, 0.01012718276419712, -0.007815893306398333, -0.010185125933193243, -0.0031401991983392255, -0.024967079711154323, 0.019005368743954545, -0.0351779595091452, -0.012180947543859047, 0.004616141147890139, -0.027065910261752237, 0.016468743912217386, 0.004223414965993466, -0.013726099337970738, -0.001629652326507923, -0.0033832387827190296, 0.022597847084359413, -0.0008015475397615716, -0.012631616429090527, -0.0043360826529626525, -0.008330943593994685, 0.0038564414847411365, 0.006785791799882994, -0.024078616544783597, -0.010191564166561994, 0.01895386287700454, -0.0027780543921134596, -0.004149376679236783, 0.01697091866439887, 0.006563676473951631, -0.018734966667757553, 0.02747795160941648, 0.029512401688972154, -0.0016377000018035321, -0.01679064999271912, -0.013944995547217728, -0.0006695657929704435, 0.00022634060575451692, 0.015786302351001417, -0.0049122952262395025, -0.034276618013391706, 0.011034959699351463, -0.002787711509335927, 0.006489637721533631, -0.003246428419109003, 0.0159408162265609, 0.007635625566041215, -0.010436213309283985, 0.017936638768549337, 0.0044873788088217095, -0.02732343587121173, 0.0046869607836237635, 0.009464054971764769, 0.007918903177653078, 0.011955613101243307, -0.006261084162233516, -0.020975436489822714, -0.002987293716968639, 0.019868077114205, 0.019919582981155006, -0.024979956177891824, -3.8628796307983905e-05, 0.008614222136929183, -0.002481900313764096, -0.019069749214996785, -0.013468573728511245, 0.009180777360152907, -0.02776122828970571, -0.027529455613721217, 0.026370592233798767, -0.031237820292118332, -0.002626758236254402, -0.013088724479013391, 0.013919243545065359, 0.0012160023518241266, 0.003801717432429389, 0.01613396136497815, 0.02102694235677272, 0.024967079711154323, 0.009953353257208752, -0.00418156738041922, -0.0162627241697079, 0.007313719019878166, -0.01802677217306658, -0.004709494134753074, 0.009367483333878776, -0.0038982895359766993, 0.001976506677728894, 0.017382958149417847, 0.0015974617417408156, 0.00010421727284204295, 0.00604218748732521, -0.01671339305493938, -0.005446660213942108, -0.0017624389106778097, 0.01051347117838636, 0.010281698502401869, -0.0035731636402986156, -0.0009262863322205198, -0.00418156738041922, -0.0126959978314554, -0.0014373131314150554, -0.00046877653299641985, -0.010082116061938498, -0.001222440468777548, -0.005028181564231748, -0.017898009368336833, -0.0013463744820654024, 0.019043996281521782, -0.013442821726358876, -0.024297512754030588, 0.01461456157301883, -0.00019032730537279761, -0.003611792574849803, -0.00710126057833861, 0.008427516163203313, -0.0025269672488533756, -0.02324165924536288, -0.025894170415092285, -0.009721580581224262, 0.007249337617513292, 0.011794659129669807, 0.014511551701764085, -0.006322246447914014, 0.000975377104957604, 0.02263647462192665, 0.01896673934374204, 0.03170136564408731, 0.05001141449744312, -0.017949515235286838, 0.003080646471000915, 0.010268822035664368, 0.0039079466531991664, -0.0038789750687011054, -0.00021728698559887277, -0.0014332893519749155, -0.0017753151445846526, -0.005179477720090805, 0.02294550609833615, 0.014949344120258064, 0.008376011227575942, -0.006180607642108083, -0.02085955015183047, 0.012953523440914893, -0.02286824729791114, 0.013429945259621375, -0.04104953520918247, 0.005688090239979724, -0.01910837861520929, 0.017524597420885094, 0.02356356532586461, -0.008041227749014073, 0.015709043550576406, -0.015593158143906797, -0.010391146607025364, 0.016442990978742383, 0.030825780807099357, -0.006109788006374459, 0.004802847121616009, -0.00418156738041922, 0.005807195694656344, 0.01438278889703434, 0.009715142347855511, 0.008350258294100937, -0.027683971351925966, -0.0012691169622090154, 0.013262553986001758, -0.0013729318454655114, 0.026113066624339272, -0.017370081682680345, 0.00031969351985787074, -0.03141808710115281, 0.007043317409342487, 0.009135710657894286, 0.01209081320801917, 0.000482457575178189, -0.014447170299399213, 0.028147516703894947, -0.015400013936812177, 0.01913413154868429, -0.001066315754307257, 0.011865478765403432, 0.024670924701482324, -0.006277179279994076, -0.014460046766136714, 0.017151185473433354, 0.03548698726026416, -0.0014381179105861493, 0.005630147070983601, -0.010725929154264598, -0.009966229723946254, -0.005237420889086928, -0.011627267856050191, -0.005871577097021218, 0.017473093416580356, 0.0024867287559600004, -0.037289666526480615, 0.010043487593048628, 0.005523918083044482, 0.021902527193760676, 0.03381307266142273, 0.021297342570324448, 0.0050474962643380005, -0.009509122605346023, -0.024915573844204317, 0.016224094769495396, 0.007661378033854901, -0.0021954033526371997, -0.014923592118105695, 0.0036311068092947383, -0.0033092002631316887, -0.015477270874591918, 0.0034218674844395587, 0.005462755797363984, -0.008556278967933059, -0.007461796059052847, 0.0041268433281074724, -0.010577852580751232, 0.017614730825402335, -0.0005235007017234964, 0.04032846424775399, -0.0018799348070122424, -0.026885643452717753, 0.005958491850515402, 0.035924779678758144, 0.00920653029362791, -0.006631276993000879, -0.017923762301811835, -0.008839556579544921, -0.006293274863415952, 0.031109057487388583, 0.004815723122692192, 0.013108038247797008, -0.008504773100983054, -0.0068179825010654315, -0.0067600393320693085, -0.00453244551108033, 0.020705034413625718, -0.015000849055885435, 0.008054104215751574, -0.010770995856523219, 0.021722260384726192, 0.015348509001184805, -0.026576611976308253, -0.020151355657139495, 0.015361384536599671, -0.0070819458782323584, -0.012934208740808641, -0.0053404312260029885, -0.012032870039023048, -0.0159536926932984, 0.009927601255056383, 0.0006558847798925067, -0.01977794370968776, 0.0002667801333695877, -0.019507541633490763, -0.0014332893519749155, -0.033349527309453744, -0.003294714470882658, 0.026447849171578507, 0.009084205722266913, -0.011981365103395676, -0.015245498198607427, -0.014460046766136714, -0.0058232912780782214, 0.10785160156198997, 0.0016288475473368292, 0.004513131276635395, 0.012721750764930402, 0.022546341217409407, 0.003920823119936669, -0.01841306058725582, -0.0049509241607906904, 0.010062801361832246, -0.002047326313462518, -0.01979082017642526, -0.014241149625567091, 0.00442943517416427, 0.016687640121464373, 0.025353366262698296, 0.0092773489980389, -0.00387575595201673, -0.0024561476131197513, -0.006405942084723822, 0.0008148261632539615, 0.0035796018736673663, -0.018400184120518318, -0.0014719181701107736, 0.02953815275980189, 0.031186316287813595, 0.011073588168241333, 0.017640483758877338, 0.028945844603103163, 0.005221325771326368, -0.01225176717959267, -0.024658048234744823, 0.022906876698123645, -0.02271373342235166, -0.0031675614573257577, -0.01910837861520929, -0.007300842553140664, -0.008253686656214945, 0.017164061940170856, 0.022481960746367168, -0.010848253725625593, 0.03700638798354612, 0.013326935388366632, 0.00840176322972831, -0.01925001788667654, 0.009122834191156785, -0.020434634200073992, -0.01420252115667722, 0.019932459447892507, -0.006393066083647638, -0.008260123958261062, 0.03474016336536069, 0.007230023383068357, -0.02450353435918534, -0.023447678987872367, 0.0015926330667142526, 0.0046869607836237635, -0.016288475240537635, -0.00813136208485395, -0.022430454879417163, -0.010056363128463496, -0.02755520854719622, -0.02200553706501542, -0.019919582981155006, -0.02080804614752573, 0.0023998140024658163, -0.04929034353601464, -0.03278297394887529, -0.007867398242025706, -0.016880783397236362, -0.004416559173088085, -0.014266902559042094, -0.008916813517324663, -0.005494946498546421, -0.0011781783128593623, 0.020009716385672248, 0.008408201463097061, 0.020962560023085212, -0.009637884478753137, 0.013494326661986248, 0.022494835350459402, -0.000663127676017022, 0.005662337772166038, 0.01227108094837629, 0.005987463435013463, -0.013764727806860609, -0.003943356471065979, -0.016365734040962643, -0.0008619050462709757, -0.007313719019878166, -0.0007556758255011981, 0.010371831906919112, -0.005923082032648589, 0.008485459332199435, 0.004455188107639273, 0.01878647067206229, 0.012914894040702389, 0.0006474347150113506, 0.013211048119051752, -0.010146497464303373, 0.00376308873070886, 0.027271930004261726, 0.0045807313300233275, -0.02639634516727377, -0.005803976577971969, 0.015387137470074676, 0.02270085695561416, 0.0094383029696124, 0.015528776741541923, -0.01957192396717827, 0.006695657929704436, 0.027426445742466474, -0.024130122411733602, 0.0377789648119246, 0.0025237481321690003, 0.014472922301551581, 0.020202861524089503, -0.021297342570324448, 0.008318068058579818, -0.0038435652508342936, -0.016932289264186367, -0.0015113516510023963, 0.005012086446471188, 0.04019969958037898, 0.017164061940170856, -0.013339810923781498, -0.010861130192363096, 0.008433954396572064, -0.014163891756464717, -0.007139889512889797, -0.01292777050743989, -0.01373897580470824, 0.03332377437597874, -0.024851193373162078, -0.00775151190403346, -0.03131507909254334, 0.014640314506493833, 0.005736376524584037, 0.007165641980703483, -0.022687980488876658, -0.009560627540973395, -0.018631956796502806, -0.0001827826170591221, 0.00037079621141885725, -0.011743154194042435, -0.008685040841340173, -0.03381307266142273, -0.015927939759823397, 0.001804286729082714, 0.007365223955505537, 0.026731127714513005, -0.044963921492734336, 0.011698087491783814, -0.011710963958521316, 0.001512961209344584, -0.0066184005262633775, -0.008472582865461934, -0.0008228738385495707, 0.01274106453371402, 0.015065230458250308, 0.03324651930084427, 0.013880614144852855, -0.001603899858694237, 0.01811690557758382, 0.014099511285422478, 0.0003297531139773822, -0.015644663079534167, -0.0027603494831800533, 0.007255775850882043, -0.009032700786639541, 0.012953523440914893, -0.003589258990889834, -0.004696617668015573, 0.0324996954059408, 0.01958480043391577, -0.027452198675941477, -0.008105609151378946, 0.008047665982382823, -0.024387648021193097, -0.015400013936812177, -0.012786132167295275, 0.0016433334560011891, -0.0009254816112570905, 0.011717402191890066, 0.003981984939955849, 0.016314228174012638, 0.007687130501668587, 0.024052863611308595, -0.009760209050114132, 0.014318407494669465, -0.013532955130876118, 0.020048345785884752, -0.010957701830249088, -0.00616129294200183, 0.0013946605338390574, 0.00022090843366113044, -0.0021438981841791693, -0.008800927179332417, 0.005916644264941156, 0.004036709457928913, 0.005420907746128421, 0.025160222986926307, 0.02094968355634771, -0.005089343849912246, 0.007127013046152296, -0.01672626952167688, 0.024799687506212073, -0.0048382569394828205, -0.0351779595091452, 0.012753941000451522, -0.03414785707130723, -0.014524427237178953, -0.021464734775266697, -0.03940137354381604, -0.02500570724872156, -0.009148587124631787, 0.006261084162233516, -0.017292824744900605, 0.01833580178683081, 0.014910715651368193, -0.005494946498546421, 0.0011202351438632397, 0.021464734775266697, 0.03615655235474263, -0.00450991215995102, -0.000663127676017022, 0.020769416747313228, 0.0010220535983890713, -0.033632805852388245, 0.030336482521655373, 0.0008059737669949232, -0.0040495854590050975, -0.00047481228946812674, 0.01658463025020963, 0.005073248732151686, -0.006290055746731577, 0.013481450195248747, -0.004567855328947143, -0.012374091750953668, -0.022971257169165885, 0.026705374781038, 0.006302932213469079, 0.019687810305170514, -0.008987633153058287, -0.007184956215148419, -0.016546000849997126, 0.0041171859780543465, -0.024748183501907335, 0.009296663698145151, -0.022353197941637423, -0.0032609142113580337, -0.014357035963559335, 0.017073928535653614, -0.014472922301551581, 0.02907460740783291, -0.016752022455151883, 0.01666188718798937, 0.0015709043783407066, -0.0035828209903517416, -0.016842155859669125, -0.012155194610384045, 0.013198172583636885, 0.009998419959467373, -0.022481960746367168, -0.013957872013955229, 0.0087944898772863, -0.00948336967187102, -0.004680522550255013, 0.000828104844954016, -0.004896200108478943, 0.023705204597331858, -0.014254026092304592, -0.0045517597455252655, -0.021606374046733944, 0.007062631643787423, -0.0054530984473108585, 0.002483509639275625, -0.008974757617643419, -0.013944995547217728, 0.01078387232326072, -0.006682781928628251, 0.026203200028856514, -0.002922912314603766, -0.005185915953459556, -0.013288305988154126, -0.019159882619514026, 0.002151945975890108, -0.027400692808991472, -0.009303101931513902, -0.004406901823034959, -0.004406901823034959, 0.0038660988347942625, -0.005408031745052237, -0.009914724788318882, 0.001669085923814875, 0.020280118461869244, -0.017382958149417847, 0.028353536446404436, 0.03839702403945306, -0.03136658495949335, 0.014266902559042094, -0.01849031752503556, 0.0146531900419087, -0.04828599775694221, 0.00527926894032249, -0.0033285147304072823, -0.005156944368961494, 0.002761959041522241, 0.031855879519646794, -0.016108208431503148, -0.0030548940031872294, 0.014756200844486077, 0.011343990244438329, 0.0034218674844395587, -0.019996839918934747, -0.010719490920895847, 0.018400184120518318, 0.03077427494014935, -0.03201039712049681, -0.046895357975744734, 0.01438278889703434, 0.008665727072556554, -0.0081378003182227, 0.019456037629186025, -0.025263232858181054, 0.00153468989771813, -0.005185915953459556, 0.01779499949708209, 0.004484159692137334, -0.020318747862081748, -0.02953815275980189, -0.03298899369138478, 0.0031884852501128805, -0.015696167083838905, -0.0159536926932984, -0.0002112512291271659, -0.015335632534447302, -0.0162498477029704, 0.02387259680227411, 0.005839386395838781, -0.004355396887407588, 0.03134083202601834, 0.01979082017642526, 0.009103519491050531, -0.003112837172183352, 0.0007114136695830124, -0.0324996954059408, 0.004938047694053188, -0.016365734040962643, -0.03391608439532274, -0.008910376215278546, -0.02158062111325894, 0.012026431805654297, 0.02186389965619344, 0.013481450195248747, -0.014704694977536072, 0.014975097053733066, -0.008723670241552677, -0.014627438039756331, 0.0013632746118277146, 0.012760379233820273, 0.0071205748127835455, -0.013713222871233237, -0.0025945675350719658, 0.02476105810599957, -0.005781443226842658, 0.021735136851463693, -0.019301521890981277, -0.02584266454814228, 0.002267832313882353, -0.009090643955635665, 0.0010735586504317723, -0.03007895691219588, -0.015374261003337174, -0.001296478988364889, 0.0227652374266564, 0.0006301322538711561, 0.007931779644390579, 0.012779693933926525, 0.004983114861973127, 0.016700516588201875, -0.021155705161502465, -0.008086294451272694, 0.005546451434173792, 0.01397074848069273, 0.008762298710442547, -0.005008867329786813, -0.021142828694764963, 0.011595077620529071, -0.021799517322505933, 0.027915744027910458, -0.0071205748127835455, 0.006637714760708313, 0.006740725097624373, 0.009605694243232018, -0.01587643575551866, -0.010822501723473224, -0.028662567922813933, -0.013571583599765989, -0.007880274708763207, -0.009798838450326636, -0.01742158754963035, 0.0241043694782586, -0.003746993380117642, -0.01966205737169551, -0.012528606557835782, 0.006714972629810688, 0.01842593705399332, 0.006714972629810688, 0.012354777050847416, 0.00033498409127799523, 0.008633535905712801, -0.006306151330153454, 0.014163891756464717, -0.016623259650422134, 0.013339810923781498, -0.009090643955635665, -0.009618570709969519, 0.0014083415469169941, 0.0036407641593478642, 0.001078387209043006, -0.02871407192711867, -0.0016127523131609402, -0.02922912314603766, 0.017151185473433354, -0.006009996786142773, -0.01619834183602039, -0.019533294566965766, -0.008144237620268818, 0.002316118365656008, 0.02263647462192665, -0.03996792690439449, -0.014395665363771841, 0.009940476790471251, 0.0072815283186957284, -0.01787225643486183, 0.008485459332199435, 0.24207378976984292, -0.014125263287574847, 0.018670584334070043, 0.011640144322787692, 0.001665866923545829, 0.012296833881851292, 0.021670754517776183, -0.013726099337970738, 0.009818152219110254, 0.019443161162448524, 0.010442651542652736, -0.001603899858694237, -0.013893490611590356, -0.0007939022540515094, 0.018078276177371316, 0.013391315859408871, -0.017099681469128616, -0.005372621927185425, -0.009122834191156785, -0.032293675663431304, -0.01613396136497815, -0.009502684371977273, -0.0074811102934977825, -0.001950754209915208, 0.005269611590269364, 0.014833457782265818, -0.013050095078800885, -0.02003546931914725, -0.005591518136432414, 0.0175889797545726, -0.002918083639577203, -0.0066763436952595, 0.015812053421831153, -0.02123296209928221, 0.00986321985269151, -0.009554189307604644, 0.0033671434321278114, -0.01733145414511311, 0.00284565467833205, 0.014395665363771841, 0.006933868839057676, -0.014781952846638446, 0.015026601989360438, -0.02562376833889529, 0.0058973295648349034, 0.028791330727543682, 0.007172079748410917, -0.005736376524584037, 0.006080816421876398, 0.03551274019373917, -0.024851193373162078, -0.004873666757349632, 0.01208437497465042, 0.022211558670170176, -0.004294234601727089, -0.016855032326406626, 0.0159665691600359, 0.0056043946031699154, -0.030336482521655373, 0.0025559388333514367, -0.0058232912780782214, 0.0024416618208707207, -0.0031514661067345395, 0.02922912314603766, -0.01802677217306658, 0.003676173744384018, -0.005420907746128421, 0.02378246339775687, 0.005137630134516559, 0.002922912314603766, -0.0006244988578811639, -0.004377930238536898, -0.01658463025020963, 0.0029808554835998886, -0.018013895706329077, -0.0020891741318674224, -0.0019330494173971312, 0.03829401230555305, 0.012753941000451522, 0.018928109943529538, -0.0020746883396183914, -0.0016803527157948596, -0.0006538728901724367, 0.00546597491404836, -0.026731127714513005, -0.04679234996713526, -0.004706275018068699, 0.007719321202851024, 0.03309200169999425, -0.01633998110748764, -0.009373921567247527, -0.015734796484051412, 0.020370251866386486, -0.013024343076648516, 0.007165641980703483, -0.008466144632093183, 0.011653020789525194, 0.017254195344688097, 0.01824566838231357, 0.017099681469128616, -0.030722769073199343, -0.011813973829776059, 0.02555938786785305, 0.005343650342687364, -0.0030532844448450417, 0.014138139754312348, -0.0162498477029704, -0.007384538189950472, 0.008350258294100937, -0.010133620997565871, -0.01032676520466049, -0.020177108590614497, -0.004500254809897894, 0.02724617893343199, 0.011601514922575187, 0.01185904053203468, 0.006035749719617776, -0.020846673685092968, 0.008240810189477444, -0.0006836492538415919, 0.005240640005771303, -0.03007895691219588, 0.0027973686265583947, 0.013339810923781498, 0.008112047384747698, -0.016546000849997126, -0.007687130501668587, 0.009309540164882652, 0.015142488327352684, -0.02871407192711867, 0.021374601370749455, -0.002757130366495678, 0.0053404312260029885, -0.017769246563607087, -0.0002983672210698717, 0.02187677612293094, 0.007674254500592403, -0.042929469550533395, -0.0013407411442830747, 0.015760549417526415, 0.013648841468868364, 0.01204574650576055, -0.00816999055374382, -0.0018284297549695414, 0.020614901009108476, -0.04094652347528246, 0.012940646974177392, 0.0011854212089838776, -0.019597676900653272, -0.007178517981779668, -0.01703529913544111, 0.0005243054226869256, -0.008318068058579818, -0.002047326313462518, 0.027812734156655715, -0.015129611860615183, -0.026074437224126768, 0.0021954033526371997, -0.014305531027931964, 0.01842593705399332, -0.01734433061185061, -0.003207799717388474, 0.03543548139331416, -0.0026412440285034327, -0.015245498198607427, -0.010577852580751232, -0.1645071760384299, 0.01733145414511311, 0.007674254500592403, -0.009921163021687633, -0.0007399828644955267, 0.01635285757422514, 0.02002259285240975, -0.038087992563043564, 0.0162498477029704, -0.005694528473348475, 0.03136658495949335, -0.006644152994077063, -0.027220425999956988, -0.01650737331242989, -0.0027040158725261183, -0.01958480043391577, 0.014498675235026584, 0.0007693568967867996, 0.018760719601232555, -0.004171910030366093, 0.027065910261752237, -0.025675274205845297, 0.018825100072274795, -0.022906876698123645, 0.011208789206339831, 0.016880783397236362, 0.0060389683706408345, 0.0071978326818859205, -0.019507541633490763, 3.1662535747574006e-05, -0.018078276177371316, -0.035280967517754676, 0.02476105810599957, 0.015554528743694292, 0.0063254655645983895, 0.0005194768640756917, -0.0019105159498524914, -0.017601854358664834, -0.01546439533917705, 0.0227781138933939, 0.02548212906742804, 0.030259223721230365, 0.020434634200073992, -0.02477393457273707, 0.005343650342687364, -0.015927939759823397, 0.021657878051038682, -0.0025398434827602185, 0.0015789520536363159, -0.019983963452197245, 0.02239182547920466, 0.008517649567720555, 0.020434634200073992, 0.003087084704369666, 0.02364082412628962, 0.01635285757422514, -0.0009600865335374795, 0.027143167199531977, -0.018734966667757553, -0.008665727072556554, -0.008047665982382823, -0.0253919956629108, 0.002789321067678115, -0.006164512058686206, 0.004017394757822661, -0.02364082412628962, -0.036414077964202124, 0.015915065155731163, -0.017382958149417847, 0.009650760945490638, -0.014588808639543826, -0.009998419959467373, 0.013571583599765989, -0.020962560023085212, -0.003454058185621995, 0.01972643970538302, -0.02910036034130791, 0.023627947659552118, 0.007796579071953399, -0.01074524385437085, -0.0019893831444663954, 0.022481960746367168, -0.019275768957506274, 0.0113954951800657, -0.00883311834617617, 0.003291495354198283, 0.007165641980703483, -0.01055209964727623, 0.011247417675229701, -0.0002418323574154987, 0.0007806236305591195, -0.022919753164861147, -0.013494326661986248, -0.012631616429090527, -0.021271591499494712, 0.021915403660498177, 0.020447510666811494, 0.00901982431990204, 0.0035087824707644008, -0.006582990708396566, 0.012187385777227798, -0.010835377258888092, -0.017009546201966107, 0.03883481645794704, 0.01268955959808665, 0.020151355657139495, 0.029512401688972154, 0.017086805002391115, 0.011228103906446083, 0.012193824010596549, -0.008433954396572064, 0.024413399092022833, 0.01788513290159933, 0.008285876891736065, -0.0008128142735338915, 0.021979785994185683, -0.013468573728511245, -0.021645003446946448, 0.011762468894148687, -0.0027667874837181456, 0.04156458642810146, -0.011968488636658175, 0.005800757461287593, 0.0018364774302651505, -0.011665896324940061, -0.0071205748127835455, -0.11619541789743162, -0.02763246548497596, 0.00022875491416396614, 0.014215397623414722, -0.0318816324531218, 0.0188894824059623, 0.011240980373183584, 0.015219746196455058, 0.0027378158992200845, 0.010944825363511587, 0.0007013541045673333, -0.001027686936171399, -0.0016457476770991414, 0.008073418915857826, 0.013024343076648516, -0.01381623274248798, 0.0036536403932547075, -0.015477270874591918, -0.012541483024573283, 0.01697091866439887, 0.014807705780113449, 0.009148587124631787, -0.0011524257286303471, -0.005485289148493295, -0.006560457357267255, -0.007062631643787423, -0.029357885950767406, 0.0054144695127596705, 0.0139965004828451, -0.016108208431503148, 0.020344498932911483, -0.018915233476792036, 0.019159882619514026, -0.015773425884263916, -0.022520588283934405, -0.00306937979543626, 0.0010172250397778376, -0.010075677828569747, 0.02902310340352817, -0.009689390345703142, -0.005298583174767425, 0.00719139444851717, -0.010461966242758988, -0.026254705895806522, 0.011846164065297178, 0.003161123223957007, -0.016095331964765647, 0.01677777352598162, 0.03260270341455027, -0.023254535712100382, -0.007397414656687974, -0.02655085904283325, -0.052380647124238025, 0.01613396136497815, 0.028662567922813933, -0.006061502187431463, 0.01288270380518127, 0.02078229321405073, -0.01979082017642526, 0.007712882969482273, -0.010094992528676001, 0.00885887034832854, -0.017176938406908357, 0.0377532118784496, 0.013726099337970738, -0.0066763436952595, -0.0214776112420042, -0.006727848630886872, -0.00496701927855125, -0.01679064999271912, 0.006267522395602266, 0.02616457249128928, -0.028250526575149693, -0.006650591227445814, -0.02080804614752573, -0.005874796213705593, -0.02286824729791114, -0.03726391359300561, -0.00188154436535443, -0.020614901009108476, -0.010249507335558116, -0.0076420637994099655, 0.009766647283482883, -0.026756880647988007, 0.010410460375808983, 0.028611062055863928, -0.009592817776494515, 0.022662227555401652, -0.01377760427359811, 0.0029084265223547354, 0.006518609306031692, 0.012753941000451522, 0.00655723824058288, -0.011337552011069577, -0.006537924006137944, 0.01116372250408121, -0.017704866092564848, 0.0008594907087576942, 0.015013725522622937, -0.0042491674338071515, -0.009882533621475129, -0.009406111802768647, -0.029744174364956646, 0.025456377996598306, -0.011189474506233579, -0.01418964468993972, 0.02855955805155919, -0.027967249894860463, 0.010758120321108351, -0.015129611860615183, -0.006721410863179438, -0.0033220764970385316, 0.004242729666099718, 0.011678772791677563, -0.0017061051836085455, 0.001773705586242465, -0.01505235492283544, -0.03164985977713731, 0.029744174364956646, -0.019868077114205, 0.01457593310412896, 0.006322246447914014, 0.002335432600100943, 0.027838487090130717, -0.0011991022220618143, 0.025507882000903044, 0.004783532887171073, 0.015193993262980056, -0.01964918090495801, 0.014884962717893191, -0.025301862258393558, 0.000964915150356378, -0.005652680422112912, -0.03739267453509009, 0.0041171859780543465, 0.0280187538991652, -0.014717571444273573, -0.035409732185129696, -0.004014175641138286, 0.027915744027910458, -0.01664901072125187, -0.013623089466715995, 0.00047159323099141596, -0.029692668498006638, 0.00798328458001795, -0.01055853788064498, -0.008459706398724433, -0.02946089582202215, -0.03682612117451164, -0.00527926894032249, 0.0033413909643141256, 0.004242729666099718, -0.009393235336031145, 0.016095331964765647, -0.014666066508646202, -0.0159408162265609, -0.018001019239591576, -0.012605864426938158, 0.005115096317725932, 0.007564805930307591, -0.004954143277475066, 0.013417068792883874, 0.010255945568926866, -0.01621121830275789, 0.018760719601232555, -0.014936468584843196, 0.004303891951780216, 0.023306041579050387, -0.009631446245384385, 0.008054104215751574, -3.2844536965222896e-05, -0.03837127110597806, -0.017395834616155348, 0.004165471796997343, 0.016468743912217386, 0.009200092060259159, 0.02009984979018949, 0.007397414656687974, 0.007024002709236235, 0.00017674686058741522, -0.01420252115667722, 0.011260294141967202, 0.024812563972949574, -0.0037437742634332666, 0.004648331849072576, 0.005208449304588867, 0.01742158754963035, 0.012631616429090527, 0.00010461965515163181, -0.008536964267826807, -0.00011548400661436286, 0.015528776741541923, -0.03126357322559333, 0.007416728891132909, 0.010011296426204875, 0.026679621847562996, -0.005591518136432414, 0.007474672060129032, -0.027658218418450963, -0.022417578412679662, 0.012296833881851292, 0.02585554101487978, 0.0009818152219110254, -0.002103659924116453, -0.020138479190401994, 0.007024002709236235, -0.011884793465509684, 0.012071499439235552, -0.01771774069665708, -0.00732659502095435, -0.0036665166271615504, 0.012567235026725652, 0.04184786497103595, -0.005665556888850413, 0.02593279981530479, 0.011144407803974958, 0.007757950137402211, 0.014923592118105695, -0.0027796639504556473, -0.015361384536599671, -0.024516408963277576, 0.019043996281521782, 0.006721410863179438, 0.0064574470203511945, 0.023962730206791353, -0.01894098641026704, -0.0023515279506921617, 0.02049901467111623, 0.006920992837981491, -0.027889991094435455, 0.014035129883057603, 0.023357545583355125, -0.010391146607025364, -0.03345253904335376, -0.03633682288906765, -0.00010275863242230961, -0.012142318143646543, -0.001191859325937299, -0.0070046884747913, 0.022134299869745164, -0.015000849055885435, 0.023203029845150373, -0.015219746196455058, -0.013520078664138617, -0.016893659863973863, 0.022095672332177928, 0.00813136208485395, 0.015709043550576406, 0.02124583856601971, -0.020988312956560215, 0.00258330085950731, 0.0029068169640125477, -0.009367483333878776, -0.0012675074038668277, -0.006573333824004757, -0.009341730400403772, -0.013429945259621375, -0.022610721688451647, -0.008594907436822929, 0.019172759086251528, -0.0306197592019446, 0.003239990418570911, 0.02365370059302712, 0.008472582865461934, 0.004748123069304261, -0.0068179825010654315, -0.01659750671694713, 0.016610383183684633, -0.015618910146059166, -0.008820241879438669, -0.015490147341329419, 0.015103859858462814, -0.0099340385571025, -0.038963581125322055, -0.003737336030064516, -0.003515220471302493, 0.015013725522622937, -0.00031466373735003115, -0.009464054971764769, -0.01119591273960233, 0.01774349363013208, -0.022147176336482666, 0.0019282207423705683, -0.01550302380806692, -0.0015878045081030188, 0.03159835763547784, 0.020241489061656737, 0.0005995511110309072, 0.013648841468868364, -0.018812223605537293]\n",
      "Embedding vector: [-0.003910388128643084, -0.0063802699036670536, 0.006868681979106717, 0.017063512511404387, -0.0014644635778681794, 0.005959864396075471, -0.003480709209827337, -0.006992330411283573, 0.01417013370366306, -0.0430297270407028, -0.009656958711458252, 0.013465336755498583, 0.004343158339753974, 0.005975320159059288, -0.01314384980738398, -0.026040403681736775, 0.030689591809637744, 0.012080472266208243, 0.026955401986713253, -0.011072735658038754, 0.003996941984600756, 0.01417013370366306, 0.003996941984600756, 0.0010610598286539328, -0.003279780100086342, -0.017657025730911314, 0.0032735977483266884, -0.03566026874829837, 0.031431483334021404, -0.0031607682571062525, 0.013675539043633111, -0.026361888767206326, -0.025867295038498904, -0.028587565203002357, -0.008408107357864075, -0.026757564867759296, 0.009372566339562832, -0.0016429812259229975, -0.0007426646384957349, 0.0032643241042718926, 0.01036175565962273, -0.01240195828300032, -0.004927398380867368, -0.013366417264699079, -0.025669457919544947, 0.02923053723658651, 0.0014582811096932103, -0.007140708716160305, -0.015443714464295853, 0.023740538093502378, 0.011511688453739928, -0.014689457770731622, -0.016123782005421715, -0.03059067231883824, -0.014578174042074073, 0.02508830893789606, 0.0022179473901509654, 0.0033786988923939524, 0.01161678913214593, -0.009712600575787027, -0.023097566059918223, -0.016000134038906124, -0.021712700639305357, -0.011845539639712575, -0.011721890741874456, -0.013094390993306754, -0.009434391254143155, -0.015740472005371844, -0.017409727935235077, -0.008315370917316116, 0.00934783693252422, 0.022590606230707706, -0.0008894973554325536, -0.01790432352658755, -0.0035981752902445397, -0.002885649994926891, -0.0011112921060891818, 0.00027531142429206457, -0.005836215498237352, 0.005425084100361828, 0.03266797044975754, -0.021044998267360063, -0.022874998602603124, 0.01710060708762357, 0.022281483520451145, 0.007183985876969772, -0.010714154133704967, 0.022182565892296693, -0.010343208371513138, -0.01690276810602456, 0.008426654645973666, 0.003530168489565827, 0.0028841044651946356, -0.007901147528653556, -0.0021731246996092423, 0.016630741834632232, -0.0034992564979369287, 0.043351212126172343, 0.005245793338194935, -0.02508830893789606, -0.006707938505049416, 0.010707972014775946, -0.021650875724725033, -0.003579628002134948, -0.0382074284069189, 0.00023783042198407428, 0.01331695845062185, -0.01026283710014575, 0.00935401905145324, -0.025187226566050516, 0.006621384649091743, 0.012711080061934355, 0.012092836504066286, -0.04411783212627209, 0.0023848729831372887, -0.00984861371148319, 0.025051214361676878, -0.01049158667638987, -0.02063695792894905, -0.005514729015784012, 0.01860912047475203, 0.03583337552889119, 0.008117532867039633, -0.010429762693132073, 0.00809898557893004, -0.008649222103288765, -0.019400470813212913, -0.018114524883399555, -0.035684997224014456, 0.010287566507184364, 0.024123849956197305, 0.032816348754634274, 0.009663140830387275, -0.0014520986415182413, -0.017842498612007228, -0.0004887985160803855, -0.03622904976679911, 0.017014051834682107, -0.005276705795485097, 0.011282937946173282, 0.003697094315382782, 0.028266078254887753, -0.012723444299792398, 0.0010069636104727295, -0.014776012092350558, 0.004030945501355429, 0.0030711231088534374, -0.013218038959822346, 0.010157735490417224, -0.04340067280289463, 0.010392668116912892, -0.019660132846747197, 0.013762093365252047, -0.025743647071983313, 0.016383444038955995, 0.017533375901750668, -0.017038782173043245, 0.017582836578472948, -0.022269119282593102, -0.009143816763318713, 0.009582769559019887, 0.015270606752380506, 0.018881146746144353, 0.01786722895036837, -0.002072660377569376, 0.006806857530187658, 0.005938225582840105, 0.001049467773585438, 0.004748107618700475, -0.004469898297056603, -0.0028918325795171756, -0.009205640746576508, -0.02633716029149024, 0.03608067146192238, -0.008612127527069581, 0.033854996888771395, -0.010788343286143334, 0.021613781148505852, -0.036278510443521386, -0.01969722742296638, -0.03336040129741892, -0.007709492528628619, 0.01426905226314004, 0.00923655320386667, -0.001456735463545639, -0.0079691545621629, 0.014466890313416525, -0.0074560126140233605, 0.01895533589858272, -0.019672498947250292, 0.031505672486459774, 0.004476080881646888, 0.024680268599485047, -0.016915134206527654, -0.6868928909961318, -0.006336992742857586, 0.026262971139051874, 0.016878039630308473, 0.011740438029984049, 0.008043343714601267, 0.015517903616734217, 0.016754389801147827, -0.015827025395668253, 0.017632295392550176, 0.012068107097027674, 0.006596654776391866, -0.015505539378876174, -0.0009544129220237816, 0.0212922960630363, -0.00989189133795392, -0.004488445585166195, -0.019177903355897818, -0.005341621303868667, 0.018893510984002396, -0.007029424987502756, 0.016235065734079266, -0.01051631701475101, -0.019437565389432098, -0.00211284601325307, -0.013972295653386575, -0.0050695941011538155, -0.03605594298620629, -0.01175898531809364, 0.02606513215745286, -0.025867295038498904, 0.010027904473650083, -0.009953715321211717, -0.024123849956197305, 0.057570804643912635, -0.011598241844036338, -0.00812371591729118, 0.0434501297543268, 0.02796932164513429, 0.02831553706896498, -0.02146540284362912, -0.005044864228453939, 0.018052701831464284, -0.01693986268224374, -0.011282937946173282, 0.0069057765553259005, 0.004469898297056603, 0.01204337768998906, 0.015443714464295853, 0.013737363958213435, 0.030541213504761012, -0.0020649322632468356, -0.002876376350872095, 0.020599863352729866, -0.00045015832281746024, 0.011301485234282874, 0.008241181764877752, -0.008309188798387095, -0.0026599912453166507, 0.006639931937201335, -0.003978394696491166, 0.017793039797930003, -0.028241347916526615, -0.0041515028740677735, 0.0003098943982810167, -0.002012381458382572, -0.01764465963040822, 0.009558039220658747, 0.0017496282489684644, 0.012086654385137265, 0.018967700136440762, 0.023827091483798787, -0.007567296808342172, 0.02519959266655361, 0.008185539900548976, 0.005517820540909785, 0.027177971306673404, -0.019771416575404745, -0.01125820853913467, 0.021675606063086172, 0.004197871094341752, -0.03380553621204912, -0.016976957258462926, 0.007480742486723237, 0.017582836578472948, -0.015060403532923452, -0.004077313721629407, 0.0062751682939385265, 0.015456079633476422, -0.006296806641512629, 0.004559543678140049, 0.01886878250828631, -0.02690594317263603, -0.003077305460613091, -0.000999235496150189, 0.008043343714601267, -0.007913512697834127, 0.03870202399827138, 0.037663375864134256, -0.020402024371130856, 0.018275269288779383, 0.0016429812259229975, 0.00860594540814056, 0.008500843798412032, 0.008006249138382084, 0.01278526921437272, -0.009910438626063512, 0.009626046254168092, 0.001180071671634022, 0.003935118001342961, 0.01818871403583792, -0.004918124736812573, -0.014095944551224695, 0.006534830327472807, 0.011536417860778542, -0.020439118947350038, 0.036550538577558765, -0.025298510294708063, 0.029007969779271416, -0.018720404203409577, -0.002284408661097423, 0.016581283020555008, 0.02301101080697676, -0.00882232981520411, -0.0015355615544267187, 0.01202483040187947, 0.002860920355057646, -0.005063411516563531, -0.006166975624745488, -0.022269119282593102, 0.014837836075608355, 0.010707972014775946, 0.02238040301125065, -0.01325513353604153, 0.03548715824241545, 0.0035023475574014395, 0.026436077919644693, -0.005792938803089147, 0.041570672467651566, -0.006652296640720641, -0.022269119282593102, -0.012086654385137265, -0.014244322856101426, 0.02168797030094422, 0.013193309552783732, -0.0425845921260726, -0.019672498947250292, -0.012049559808918081, -0.008265911171916364, 0.02209601063935523, -0.017125335563339655, 0.001975286882163389, -0.015604457938353154, -0.0017017143825469145, -0.027301619273189, -0.0019582853566166847, 0.03219810333412115, -0.0037898307559307396, -0.019932160980784572, -0.005663107786322007, 0.008945978713042228, 0.006411181895295951, 0.00010374893651877086, -0.012265945147304159, -0.02571891673362217, -0.011369492267792219, -0.010961451929381206, 0.0397406721324085, 0.004352431983808769, -0.015740472005371844, 0.007418918037804177, -0.01804033573096119, 0.006868681979106717, 0.007369458758065687, -0.010429762693132073, 0.005990776387704369, -0.03128310502914467, -0.0443156711078711, -0.006182431853390569, -0.005486908083619625, 0.02611459283417514, 0.0019412835982393485, -0.020278376404615262, -0.009261282610905284, -0.0006112879755810233, -0.015839389633526296, 0.011993917944589308, 0.031752968419490955, -0.028513376050563994, 0.02777148452618033, 0.0005498500255103435, -0.00103169336675729, -0.020933714538702512, 0.0023508696992132483, -0.0035641720063204992, -0.017830134374149185, -0.0008601308353282529, 0.013007836671687818, 0.004241148255151221, 0.00727672231751773, 0.008024796426491674, 0.004472989356521114, 0.0063802699036670536, -0.007598208799971071, 0.004544087449494969, -0.0007167756767043249, 0.020179456913815758, -0.02291209317882231, 0.010998546505600388, 0.014850201244788924, 0.019338647761277646, -0.018411281493153017, -0.032643241974041455, 0.012995471502507247, -0.031827157571929325, 0.025892025376860042, -0.0012751265231956785, 0.024816280803858684, 0.015752836243229887, -0.013724998789032864, -0.012432870740290482, -0.011270573708315239, 0.02035256555705363, 0.00043122462317097594, -0.013267498705222099, -0.008333918205425709, 0.008327736086496687, 0.021885809282543228, 0.007072702148312224, -0.008389560069754482, -0.030145537404208046, -0.0028593748253253905, 0.011425134132120993, 0.0032303205875172207, -0.01565391675243038, -0.00949621523740095, -0.017261349630358344, -0.015307701328599689, 0.03788594332144935, 0.008673951510327377, 0.006411181895295951, -0.007375641342655973, 0.004683192110316905, -0.0096074989660585, 0.010670877438556763, -0.001258124881233658, 0.04406837517483992, -0.0031035808630452224, -0.02268952572150721, 0.006800674945597373, 0.017793039797930003, -0.011184019386696303, 0.00036225186640960363, 0.012711080061934355, 0.012117566842427426, -0.043252294498017894, 0.023542700974548417, -0.008197905069729547, 0.022578241992849662, 0.02668337571532093, 0.00180681575944481, -0.003083487812372744, -0.0056723814303768025, 0.000884087768539028, 0.03286580943135655, -0.015567363362133971, -0.00021503270883206323, -0.004068040077574612, 0.012834728959772473, 0.009026350915732142, -0.01645763319139436, -0.016791484377367008, 0.013737363958213435, -0.014738917516131374, -0.0036692733832183948, -0.012383410994890728, 0.009446755492001198, 0.006565742784762968, 0.024593713346543585, 0.01492439039722729, 0.02140357979169385, -0.029255267574947653, -0.007987701850272491, 0.023270672840511042, -0.021193376572236796, -0.017755943359065766, -0.0017218073168040772, -0.007975336681091922, -0.009403478796852993, 0.000596604686425044, -0.0011754348496066241, 0.015221147006980754, 0.002741908512077557, -0.0010224197227024943, 0.02242986368797293, -0.0016197971157860082, 0.03026918723336869, -0.03217337485840507, -0.012290674554342771, 0.004692465754371701, 0.01455344463503546, -0.024704997075201136, 0.01000317506661147, -0.024853375380077865, -0.006142246217706875, 0.012074289215956695, -0.004658462237617029, -0.005162330541701773, 0.001496148450778521, 0.012908918112210838, -0.0057032934220057, -0.0006943643896411211, -0.00727672231751773, 0.012748174638153536, -0.03476999519374788, -0.008129898036220202, -0.011010910743458432, -0.012983107264649204, 0.024383511989731585, 0.027499456392142956, -0.00695523583506439, -0.0034497969853678075, -0.03598175383376792, 0.0013276772116446263, 0.10208431845867286, 0.028810132660317456, 0.005811486091198739, 0.014528715227996846, 0.03130783350486076, 0.014256688025281997, -0.014009390229605758, -0.03991377891300132, -0.0008423563120847892, -0.009261282610905284, 0.007078884267241245, -0.013663174805775068, 0.00989189133795392, 0.013490066162537197, 0.008556485662740806, -0.011140741760225573, 0.0014482347007722868, 0.01149932328455936, 0.025014119785457697, -0.0009806882080405977, 0.008809965577346066, -0.010677059557485784, -0.022887362840461167, 0.022701889959365253, 0.022269119282593102, 0.026609186562882563, -0.002060295441219438, -0.013873377093909596, 0.005044864228453939, -0.001398002423337038, -0.01742209217309312, 0.01750864742603458, -0.015258241583199937, 0.0005846261907158276, 0.006658479225310925, 0.02168797030094422, -0.0017001687363993431, 0.008612127527069581, 0.023728173855644335, -0.014244322856101426, 0.0075611142237518875, 0.02089661996248333, 0.01520878276912271, -0.023320133517233322, 0.018918241322363537, -0.009378749389814381, -0.004958310372496267, 0.015616823107533723, 0.009273647780085853, -0.015010944718846226, 0.01958594369430883, -0.0017604474227555155, 0.009038715153590185, -0.01540661988807667, -0.003579628002134948, 0.012649255147354032, -0.007041789691022062, 0.009972262609321308, -0.015542633955095357, -0.01622270149622122, -0.022701889959365253, -0.015270606752380506, -0.007202533165079364, 0.008179357781619954, -0.005962955455539981, -0.034102292821802584, -0.009372566339562832, -0.00046909202246394455, -0.028142430288372162, -0.002860920355057646, 0.01659364725841305, -0.026089862495814003, -0.014034120567966898, 0.02189817352040127, -0.006609019479911173, 0.011264390658063691, -0.0010007811422977604, -0.03224756401084343, 0.005258158507375505, 0.004299881178944505, -0.006813040114777943, -0.013131485569525937, 0.01719952471577802, 0.015456079633476422, -0.0033756078329294417, -0.01241432345218089, 0.02480391656600064, 0.013588985653336702, 0.00016586305584731232, 0.0176941203071305, 0.013551891077117519, 0.011320032522392465, 0.012970742095468635, -0.01707587674926243, 0.005394171643071667, -0.006516283039363215, 0.008649222103288765, 0.008259729052987342, -0.011054188369929163, -0.0017820860031602496, 0.02984878079445458, -0.01630925488651763, -0.010238106761784611, 0.001822271755259259, 0.005171604185756569, 0.0055549151171289685, -0.0036043578748348247, 0.0108625324385817, 0.012958376926288066, -0.0036352698664637224, 0.018980066236943857, -0.009279829899014875, -0.008902702017894023, 0.0022225842121783635, -0.026139321309891227, -0.0017743578888377092, 0.003650726095108803, 0.00897689117033239, -0.002210219275828425, -0.010670877438556763, -0.013131485569525937, -0.03200026807781225, 0.001491511628751123, 0.0035827192944300904, 0.004955219313031756, -0.01038030294773232, -0.001826908577286657, -0.05247648160138147, -0.03244540299244244, -0.00388874954823835, -0.009193276508718465, 0.003088124634400142, 0.0033725165406342994, -0.03501729485206916, -0.030170267742569184, -0.027326349611550137, 0.005415810456307032, 0.00825354693405832, -0.008915067187074592, -0.0023462328771858506, -0.02120574081009484, 0.0007851688598161014, -0.011610607013216907, -0.009156181932499282, -0.012148478368395062, -0.02404966080375894, -0.002381781923672778, 0.002918107749118676, -0.018423647593656115, 0.025125403514115244, -0.0016321620521359463, -0.009792971847154415, 0.013354053026841034, 0.012352498537600568, -0.0060680570652685084, -0.01833709234071465, 0.006936688546954798, 0.006460641175034441, 0.01428141743232061, 0.028686484693801865, 0.03293999858379492, -0.018262903188276284, 0.02705432147751276, 0.001881004911883176, -0.014714188109092762, -0.008704863967617538, 0.0007341637593070669, -0.008877971679532883, -0.04659080635774436, 0.020513308099788404, 0.022281483520451145, -0.0024899743600351847, 0.02633716029149024, -0.01698932335896602, -0.01995688945650066, 0.007796046384586292, 0.006281350878528811, -0.005941317107965879, -0.014627633787473827, -0.005520911600374296, -0.0024235133219193588, 0.007313816893736913, -0.016840945054089288, 0.03810851077876445, 0.007585844096451764, -0.01520878276912271, 0.004377161856508645, 0.014244322856101426, 0.008877971679532883, -0.010571958879079784, 0.028043510797572658, 0.012636890909495989, 0.011561147267817155, 1.590285782304838e-05, 0.0028145521347836674, -0.0025579811607138975, -0.010553411590970193, 0.0073385467664367895, -0.008785235238984926, 0.020933714538702512, 0.002853192240735106, 0.0043617056278635645, -0.025249051480630835, -0.0031360386172370074, -0.008105167697859062, 0.02286263250210003, 0.0015309247323993208, -0.021057362505218107, 0.023926010974598292, -0.02680702368183652, 0.0005521684365240424, -0.011740438029984049, -0.02655972774880534, -0.041051348400583, 0.024272228261074034, 0.003749644887416414, -0.007876418121614943, 0.012228850571084976, -0.01602486251462221, -0.025867295038498904, -0.026831754020197662, -0.005848580667417922, 0.023109930297776266, -0.0013384965018469932, 0.02873594350787909, 0.027103782154235038, -0.010287566507184364, -0.022874998602603124, 0.019907430642423434, -0.005601283337402947, 0.007641485960780538, 0.01204337768998906, -0.00113679462723987, -0.011548783029959112, -0.005851671726882433, -0.0060278709639235515, 0.03420121417524714, 0.009860978880663758, -0.011536417860778542, 0.026831754020197662, 0.03219810333412115, 0.01622270149622122, -0.0038052867517451884, -0.028983241303555327, -0.030788511300437253, 0.02215783555393555, -0.017459186749312305, -0.021218106910597934, -0.025892025376860042, -0.019004794712659947, 0.0008083529699530907, 0.020488579624072318, -0.033657157907172386, 0.018460742169875297, 0.007820776257286168, 0.01010827574501747, 0.009397296677923972, -0.01051013396449946, 0.003248867875626812, 0.0009296831657392211, 0.017273713868216387, 0.008117532867039633, -0.0028686484693801863, -0.008259729052987342, -0.0012805362265045199, -0.005035590584399144, 0.013774458534432618, 0.003527077430101316, -0.006732668377749292, 0.024383511989731585, -0.023134660636137405, -0.010139188202307631, 0.018312363864998564, 0.015456079633476422, 0.007239627741298547, 0.01938810657535487, -0.0005598964926389248, -0.015987767938403025, 0.022083646401497185, -0.024123849956197305, 0.003523986137806174, 0.00722726303777924, -0.012723444299792398, 0.013230404129002915, -0.011456046589411155, -0.015122228447503775, -0.008902702017894023, -0.01073270142181456, -0.02606513215745286, -0.017125335563339655, 0.023641618602702873, -0.009156181932499282, -0.01277290404519215, 0.010194830066636407, 0.015493174209695605, -0.0038176516880951265, 0.012612160571134848, 0.01607432319134449, -0.0395181046750934, 0.008809965577346066, 0.011233479132096056, 0.00486866499141282, 0.0032055909476479756, 0.007357094054546381, -0.003969121052436369, -0.01690276810602456, 0.014516350058816277, -0.0014126856542853593, -0.017224255054139163, -0.00480374948302925, -0.006219526429609752, 0.003904205776883431, -0.019264456746194227, -0.022306213858812284, 0.014726552346950805, 0.015987767938403025, -0.004658462237617029, -0.03642688874839812, -0.0036661820909232525, 0.03867729552255529, 0.005851671726882433, 0.014528715227996846, 0.03172823994377487, -0.026361888767206326, 0.0065781074882822746, 0.016952228782746836, 0.030046617913408537, -0.012482329554367708, -0.017496281325531486, 0.0024420606100289503, 0.005715658125525007, 0.015517903616734217, 0.01417013370366306, -0.03964175450425405, 0.0020432936828421017, 0.011357127098611648, -0.009558039220658747, 0.01869567386504844, -0.0051221449060180795, 0.018572025898532844, 0.014602904380435213, 0.017657025730911314, -0.0219476323344785, 0.0063802699036670536, -0.014392701160978159, -0.01481310666856974, -0.011381857436972788, -0.011666248877545683, -0.018460742169875297, -0.012476147435438687, -0.007919694816763148, 0.007177803292379488, 0.02338195656916859, -0.010738884472066107, -0.031827157571929325, 0.012074289215956695, -0.021589052672789762, 0.015913578785964663, 0.014874930651827538, -0.01188881633486078, 0.018633848950468115, 0.0008276730811364679, -0.02041439047163395, 0.053762425668549774, 0.01557972853131454, 0.0172489853925003, 0.0033385132567102585, -0.0034374320490178694, -0.0017805403570126783, -0.01175898531809364, 0.001972195822698878, -0.012408140401929342, -0.0014428249974634455, -0.025842564700137766, 0.0025564356309816416, -0.002109754953788559, 0.0023307768813714013, 0.016148512343782857, -0.012080472266208243, 0.013094390993306754, -0.004853209228429003, -0.013205674721964303, -0.004219509907577118, 0.020204187252176896, 0.014318512008539792, -0.019672498947250292, -0.03311310536438774, -0.015381890481038055, 0.007820776257286168, 0.0008469931923198449, 0.007097431555350837, 0.017372633359015895, -0.0015494720205089124, -0.023703443517283193, -0.016803850477870107, -0.012575065994915665, -0.014825471837750312, -0.03578391485216891, 0.0026074406732830182, -0.002353960991508391, -0.01685330929194733, 0.013242769298183486, -0.003777465819580801, -0.0021916719877188334, -0.005171604185756569, -0.011660066758616661, -0.013588985653336702, -0.007721857232147926, -0.0011321578052124722, -0.012278309385162202, -0.0034838002692918484, -0.003650726095108803, 0.0013964567771894668, -0.008939796594113206, -0.006918141258845207, 0.010102093626088448, -0.01738499759687394, -0.004476080881646888, 0.0009134542886433285, 0.002401874741514625, 0.004043310204874736, 0.027548917068865236, -0.016692566749212556, -0.001587339361594223, 0.00512523596548259, -0.004278242831370403, 0.012921282350068883, -0.008179357781619954, -0.0018717312678283803, -0.0016213427619335794, -0.022541147416630478, -0.035239862309384265, 0.0266339169012437, 0.02893378062683305, -0.022664795383146072, 0.025137767751973288, 0.22415024367369213, -0.007752769689438087, -0.026757564867759296, 0.017125335563339655, 0.027227430120750632, 0.02041439047163395, 0.005808394566072965, -0.006077330709323305, 0.0001839273513636595, 0.004704830457891007, 0.007332364181846505, -0.02799405198349543, -0.01707587674926243, 0.008908884136823045, 0.02440824046544767, -0.00822881659569718, -0.016012498276764167, -0.004905759567632003, -0.025051214361676878, -0.019140808779678633, -0.0018980065538451963, -0.02594148419093727, 0.006114425285542488, -0.013502431331717767, 0.025817836224421676, -0.006386452022596075, -0.028142430288372162, 0.012290674554342771, 0.029601482998778343, 0.0041916889754127305, -0.001051786184599137, -0.00020556585900882108, 0.006621384649091743, -0.005236519694140139, -0.0019196451342499304, -0.0030324827700713673, 0.011394221674830831, -0.013366417264699079, -0.010337026252584116, 0.02277607911180362, 0.007474559902132951, 0.005180877829811365, 0.009947533202282696, -0.010639964981266603, 0.004772837491400352, -0.0008369467251912636, -0.006479188463144033, -0.006720303208568722, -0.005397263168197441, 0.0058053035066084535, -0.003366334188874646, -0.026955401986713253, 0.015592092769172583, 0.03153040096217586, -0.021354119114971568, -0.0052921615584689136, 0.020142362337596576, 0.012908918112210838, 0.023134660636137405, -0.025990943005014495, -0.003282871392381484, 0.03919661958962385, -0.018398917255294973, -0.00974969515200621, -0.027573645544581322, 0.01303256607872643, -0.020315470980834447, 0.012933647519249452, -0.013712633619852295, 0.011598241844036338, -0.0005765117521678813, -0.0044915366446307056, -0.007437465325913769, 0.0005996958623048707, -0.006806857530187658, -0.011357127098611648, 0.01049158667638987, 0.04513175178469313, 0.038528913492388454, -0.0024667902498981954, -0.02945310469390161, 0.00751783706294242, -0.014639998956654396, -0.012371045825710159, -0.008346283374606278, -0.0425845921260726, 0.01949939030401242, 0.0007465286374493472, -0.0032612328119767504, -0.012983107264649204, 0.02294918775504149, 0.0009814610893220412, 0.0028995604610090845, -0.008772871001126883, 0.018918241322363537, 0.014318512008539792, 0.0010826984090586667, 0.014429795737197342, -0.007598208799971071, 0.000716389294271261, -0.0070108776993931645, -0.06949053343606358, 0.023184119450214632, 0.007734222401328495, 0.009211823796828058, 0.004902668508167492, 0.028463915373841714, -0.006151519861761671, 0.018856416407783214, -0.004791384779509944, -0.014034120567966898, -0.04075459179082954, 0.009205640746576508, 0.013502431331717767, -0.0034065200573889713, -0.016346349462736814, 0.008550303543811784, -0.002881013172899493, -0.006683208632349539, 0.009718782694716049, 0.012235032690013997, -0.00046561440594339613, -0.012463782266258116, 0.01736026912115785, -0.005514729015784012, -0.031035807233468434, -0.015493174209695605, 0.01112837752236753, -0.00525197592278522, -0.057669725997357195, 0.022306213858812284, 0.005990776387704369, 0.014516350058816277, -0.01843601183151416, -0.016432904715678275, 0.011048005319677616, 0.002040202623377591, -0.013588985653336702, -0.016791484377367008, 0.031233646215067447, -0.0217250648771634, -0.009032533034661163, 0.015381890481038055, -0.01277290404519215, 0.009972262609321308, -0.013156214976564549, 0.028983241303555327, -0.03838053518751172, -0.014998579549665656, -0.0071283440126409985, -0.017459186749312305, -0.021477768944132215, -0.0022921365425893313, -0.027672565035380826, 0.020834795047903008, -0.004132955585958182, -0.04184270060168894, 0.004349340924344258, -0.007511654478352134, 0.03909769823617929, -0.01816398556012183, 0.0018640031535058401, 0.020389660133272813, -0.009168546170357325, -0.014009390229605758, 0.004766654906810067, -0.15629187904185282, 0.022108376739858326, -0.005709476006595986, -0.029354187065747158, 0.002582710800583142, -0.003366334188874646, 0.006012415200939735, 0.014874930651827538, -0.03936972637021667, -0.010553411590970193, 0.0070108776993931645, 0.023344861992949408, -0.03573445790073674, 0.01785486284986527, -0.004043310204874736, 0.0021313933013626615, -0.008513208967592601, -0.0006282896175430435, 0.02329540317887218, 0.006751215665858883, 0.02000635013322294, -0.00849466167948301, 0.015975403700544982, -0.01415776853448249, 0.0076662153678191515, -0.004395709144618237, -0.004667735881671824, 0.009211823796828058, -0.002542525164899448, -0.016408174377317137, -0.020031078608939025, 0.011963005487299146, 0.017632295392550176, 0.01051631701475101, 0.025619997242822667, -0.0058825837185113306, 0.0035394421336206227, 0.006973783123173981, -0.015418985057257239, 0.013354053026841034, 0.014887295821008107, 0.01325513353604153, 0.008544120493560237, 0.012061924978098652, -0.02987351113281572, 0.02493993063301933, 0.022491686739908198, 0.012859458366811086, 0.005808394566072965, -0.0199816197948618, -0.00303557406236651, -0.006992330411283573, -0.006936688546954798, -0.0011507050933220635, 0.02103263402950202, 0.0408287809432679, 0.003913479188107595, 0.005758935286334475, 0.015109863278323204, -0.01265543819760558, -0.011295303115353853, -0.024531890294608318, -0.008952161763293776, -0.001896461024112941, -0.0011360218623737422, 0.00027878904081261294, -0.00259507573693308, 0.010046451761759674, -0.01635871556323991, 0.010219559473675019, -0.00382383403985478, -0.023443781483748913, 0.013613715060375316, -0.012760539807334107, 0.003282871392381484, 0.0022643156104249443, -0.03808377857775826, 0.021440674367913033, -0.0071283440126409985, -0.0034405233413130117, -0.006627566768020765, 0.03311310536438774, -0.018510200983952525, 0.010312295914222976, -0.024977025209238512, 0.0038021956922806776, 0.013292228112260713, -0.0014876476880051688, -0.024185673008132572, -0.015245877345341894, 0.005629104269567335, -0.018547295560171706, 0.00989189133795392, -0.021255201486817116, -0.0025239778767898566, 0.015357161073999443, 0.046541345681022084, 0.018176349797979875, 0.006918141258845207, -0.007394188630765564, 0.0021283022418981503, -0.002310683830698923, -0.020167092675957714, 0.002340050525426197, 0.00530143520252371, 0.0023137751229940656, 0.009273647780085853, 0.012358681587852116, 0.010813073624504474, 0.004556452153014276, -0.021366485215474667, -0.007251992444817854, 0.008970709051403368, -0.002236494678260557, 0.0032581415196816076, 0.01316858014574512, 0.012037194639737512, 0.00746837778320393, 0.011289120996424831, -0.036723645358151584, 0.026213510462329594, -0.007381823461584994, 0.0046368238900429265, 0.014108309720405264, -0.0037898307559307396, -0.0035610807140253565, -0.08091567036215215, -0.008507025917341053, 0.005072685160618326, -0.009248918373047239, -0.0001767789125541163, 0.016519458105974685, -0.0027094507578857715, 0.03373134705961075, -0.022145471316077508, -0.0019196451342499304, -0.014194863110701674, -0.0060927864723071224, -0.0032519591679219546, -0.014800741499389172, 0.023072835721557085, -0.017743579121207723, 0.013094390993306754, -0.013415877010098831, -0.0217250648771634, 0.015134593616684344, -0.010448309981241665, 0.0014853292769914698, -0.014194863110701674, -0.0075611142237518875, -0.010763613879104721, 0.016037228615125305, -0.028686484693801865, 0.018596754374248934, 0.023097566059918223, 0.00808043829082045, 0.008408107357864075, 0.005384897999016871, -0.005848580667417922, -0.029947700285254085, -0.027301619273189, -0.019734321999185563, -0.014763646923169988, 0.021823984367962904, 0.0015201054421969539, -0.031827157571929325, 0.008933614475184185, 0.012068107097027674, 0.019029525051021085, -0.0366741846814293, -0.011604424894287885, 0.004788293254384169, -0.005650742617141437, 0.029997159099331313, 0.0027589102704548927, -0.028587565203002357, 0.0001887573791595038, -0.03002188943769245, -0.024123849956197305, -0.008216452357839138, 0.022108376739858326, 0.001517787031183255, 0.0005162330658117089, 0.012859458366811086, 0.003783648404171086, -0.01331695845062185, 0.008309188798387095, 0.00217776152163664, -0.003938209060807472, 0.04231256399203522, 0.002942837621818552, 0.025496349276307072, -0.012241214808943019, -0.01303256607872643, 0.00740655333428487, -0.015592092769172583, -0.02166324182522813, 0.03064013299556052, -0.0167049309870706, 0.011394221674830831, -0.0038021956922806776, -0.014961484973446473, -0.012735809468972967, -0.017805404035788047, 0.008061891002710857, 0.012346316418671547, -0.0007700991882270583, -0.014887295821008107, 0.01340351184091826, -0.012983107264649204, 0.005996958972294654, 0.02445770114216995, -0.009100540068170508, -0.021613781148505852, -0.0004200189505355451, 0.01546844480265699, 0.04624458907126862, 0.014578174042074073, 0.019882700304062292, -0.014145404296624448, -0.01807743030718037, -0.002513158470172174, -0.015493174209695605, -0.017014051834682107, 0.017805404035788047, -0.0025579811607138975, -0.014194863110701674, -0.007437465325913769, -0.037490265358251326, 0.021873443182040132, 0.004064949018110101, -0.008859424391423293, -0.011975370656479715, 0.0010927448179795902, -0.027895132492695925, -0.0025347970505769078, -0.003978394696491166, 0.005289070499004403, -0.03153040096217586, 0.0042040536789320375, 0.007690945240519028, 0.00025251369658813906, 0.00278673120261928, 0.01685330929194733, 0.010058816930940243, -0.0029845690200651334, 0.003882567196478697, 0.0012225759511620465, -0.011660066758616661, -0.012068107097027674, -0.0030757599308808355, 0.013242769298183486, -0.01576520048108793, 0.00832155303624514, 0.001182390082647721, 0.0266339169012437, -0.011301485234282874, -0.008389560069754482, 0.013131485569525937, -0.019289187084555365, 0.009996992016359922, 0.024358781651370443, -0.007270539732927445, -0.020080539285661305, 0.0015432895523339433, 0.021589052672789762, 0.014763646923169988, -4.909720264057283e-05, -0.029576754523062257, -0.020649322166807094, 0.035140940955939705, 0.00822263447676816, -0.023134660636137405, -0.02557053842874544, -0.0009582769209773939, -0.005224154990620833, 0.008921249306003614, -0.00822263447676816, 0.015233512176161325, 0.019907430642423434, -0.00550854689685499, -0.008117532867039633, -0.0017341721367386995, -0.012711080061934355, -0.012748174638153536, 0.011227296081844508, -0.016321620987020728, -0.021094457081437288, 0.0013052659827890805, 0.020884255724625288, 0.024556618770324404, 0.017718848782846585, 0.02720269978238949, 0.022170199791793594, -0.021799254029601766, -0.0005177786537516223, -0.0005413492045293334, -0.03390445756549367, 0.010176282778526814, 0.0023215032373166055, 0.026930673510997167, 0.014071215144186081, 0.016568916920051913, 0.0024528797838160015, -0.012686349723573215, -0.0025610724530090397, 0.004921215796277084, 0.0077774990964767, 0.005681655074431598, 0.02391364673674025, -0.009502397356329973, 0.007251992444817854, 0.026386619105567465, 0.013218038959822346, -0.007610573503490377, -0.0008469931923198449, 0.014899660990188676, 0.013984660822567146, -0.042139457211442403, -0.003530168489565827, -0.005057229397634509, 0.02834026740732612, 0.007975336681091922, 0.01622270149622122, -0.0008245818470489833, -0.001006190729191286, -0.006936688546954798, 0.021057362505218107, -0.0009296831657392211, -0.003514712493751378, -0.008562667781669827, -0.010083546337978857, -0.016742025563289784, 0.015258241583199937, -0.013378782433879648, -0.02821661944081053, 0.0033045097399555866, 0.006973783123173981, -0.0007797592147149179, -0.0028593748253253905, 0.004188597450286957, 0.013205674721964303, -0.007888783290795513, 0.013292228112260713, -0.015048039295065409, -0.014578174042074073, -0.008049525833530288, -0.007567296808342172, -0.007350911469956096, 0.022887362840461167, -0.003248867875626812, -0.012735809468972967, 0.015888850310248573, 0.006639931937201335, -0.0063029892261029135, -0.010949086760200635, 0.012822363790591903, -0.021193376572236796, 0.00959513379687793, 0.0016692566283551293, -0.003381790184689095, -0.005032499524934632, -0.02289972707831921, 0.008482296510302441, -0.021069728605721202, 0.01719952471577802, -0.0009675505650321897, 0.03348405112657957, 0.01596303946268694, -0.009162364051428304, 0.01833709234071465, -0.008636856934108194, 0.01685330929194733, -0.004262786602725323, 0.00708506685183153, -0.0009791426783083423, -0.02816715876408825, 0.006596654776391866, 0.02557053842874544, 0.005156147957111488, -0.020167092675957714, -0.025001753684954598, -0.02611459283417514, 0.01050395184557044, 0.0036352698664637224, -0.02782094334025756, -0.010435944812061096, 0.026485538596366973, 0.01585175573402939, 0.029527293846339977, 0.00620097914150016, -0.025298510294708063, -0.024420606565950766, 0.02962621333713948, 0.009051080322770756, -0.022306213858812284, -0.01391047167012878, -0.0006054919480467758, 0.0076662153678191515, 0.008902702017894023, 0.005755844226869964, 0.021712700639305357, -0.0018191805793794326, 0.009743513033077189, -0.010349390490442159, 0.0033199659686006674, 0.033261483669264465, -0.010405032354770935, 0.011326215572644014, 0.002876376350872095, -0.04065567043738498, -0.0037372799510664756, -0.01153023574184952, -0.020698780980884318, 0.0027975503764063312, 3.320642063279967e-06]\n"
     ]
    }
   ],
   "source": [
    "for embedding in [embedding1, embedding2, embedding3]:\n",
    "    print(f\"Embedding vector: {embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the embeddings in place, we can use Math concepts to study their similarity.\n",
    "\n",
    "For example, we can recall from 2D algebra that the *dot product* operation between two vectors provides us with a number that reflects whether two vectors are aligned: the greater their dot product, the more aligned the vectors are.\n",
    "\n",
    "The same concept can be applied to vectors with more than two dimensions, and NumPy package can help us with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664565515783483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650815196622498"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573246926801385"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dot product between the first and second vector is greater than the dot product between the first and third, and greater than the dot product of the second and third, which means they are *similarly oriented*.\n",
    "\n",
    "Note also that the degree of *dissimilarity* between the first and the third vector, and the second and the third vector is almost the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector stores\n",
    "\n",
    "Embedding vectors and the chunk they represent are stored in vector stores.\n",
    "\n",
    "[Chroma](https://github.com/chroma-core/chroma) is a popular vector store that is both lightweight and in-memory.\n",
    "\n",
    "It can also persist the database content in regular files, which makes it very easy to get started with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the latest versions of Chroma requires a more modern version of sqlite3 than the one packaged with Python, it is necessary to run the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Chroma in LangChain, you should start by importing the corresponding package and configuring the path where the files will be stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_path = \"./chroma_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to remove any old db files that might be in the `chroma_data/` directory from previous runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $persist_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can instantiate the Chroma DB client that represents the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the client `vectordb` to interrogate the database contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vectordb._collection.count() == len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n",
    "With the vector store set up, you can start interrogating the PDFs to get specific answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email I can use to ask for help?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides the `similarity_search()` method to do so. You just need to provide a value for the parameter `k` which tells LangChain the number of documents to retrieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can browser the results of invoking such method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we'll start to  talk a bit about machine learning.  \\nBy way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \\nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I'm actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA — he's head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So all right, online resources. The class has a home page, so it's in on the handouts. I \\nwon't write on the chalkboard — http:// cs229.stanford.edu. And so when there are \\nhomework assignments or things like that, we  usually won't sort of — in the mission of \\nsaving trees, we will usually not give out many handouts in class. So homework \\nassignments, homework solutions will be posted online at the course home page.  \\nAs far as this class, I've also written, a nd I guess I've also revised every year a set of \\nfairly detailed lecture notes that cover the te chnical content of this  class. And so if you \\nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \\nall the math and equations and so on  that I'll be doing in class.  \\nThere's also a newsgroup, su.class.cs229, also written on the handout. This is a \\nnewsgroup that's sort of a forum for people in  the class to get to  know each other and \\nhave whatever discussions you want to ha ve amongst yourselves. So the class newsgroup \\nwill not be monitored by the TAs and me. But this is a place for you to form study groups \\nor find project partners or discuss homework problems and so on, and it's not monitored \\nby the TAs and me. So feel free to ta lk trash about this class there.  \\nIf you want to contact the teaching staff, pl ease use the email address written down here, \\ncs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results look good. We can also explore the metadata of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata[0]: doc.metadata={'page': 5, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf'}\n",
      "metadata[1]: doc.metadata={'page': 5, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf'}\n",
      "metadata[2]: doc.metadata={'page': 5, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"metadata[{i}]: {doc.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NOTE: |\n",
    "| :---- |\n",
    "| The page indices start from zero, so `\"page\": 5` actually refers to page 6 in the document. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `persist()` method to save the state of the `vectordb` in the file system, so that you don't need to go through the documents again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with similarity search alone, we can obtain pretty good results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we'll start to  talk a bit about machine learning.  \\nBy way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \\nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I'm actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA — he's head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How does the instructor introduce himself?\"\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this, we might wonder whether we need to invoke the LLM at all &mdash; isn't the similarity search sufficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is no. We can outline a few drawbacks of using the similarity search alone.\n",
    "\n",
    "The most evident issues, is that we see repetition in the results retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about matlab?\"\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that because we loaded the same document twice:\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf\"),\n",
    "]\n",
    "```\n",
    "\n",
    "the semantic seach is returning the same chunk twice, which is not very helpful.\n",
    "\n",
    "That is something that might (and will) happen in real-world scenarios, as you cannot always control the quality of ingested data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another less evident issue is that restricting the search to a particular portion of the total information that has been loaded does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about regression in the third lecture?\"\n",
    "docs = vectordb.similarity_search(question, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectations is that all the metadata should come from the document `data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf`, but the reality is that the results do not take into account that fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata[0]: doc.metadata={'page': 0, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "metadata[1]: doc.metadata={'page': 2, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf'}\n",
      "metadata[2]: doc.metadata={'page': 14, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "metadata[3]: doc.metadata={'page': 13, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "metadata[4]: doc.metadata={'page': 17, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf'}\n",
      "metadata[5]: doc.metadata={'page': 0, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf'}\n",
      "metadata[6]: doc.metadata={'page': 6, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"metadata[{i}]: {doc.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some responses come from the third lecture, but some others come from other documents.\n",
    "\n",
    "This happens because the question includes a piece of structured information (*\"bring results from the 3rd lecture\"*) mixed with semantic information (\"*bring results about regression*\"), and the similarity search is simply doing a semantic lookup based on embeddings.\n",
    "\n",
    "As a result, the structured information is not taken into account, because that part is not captured in the semantic embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prove that by examining the results that have been retrieved from the second lecture.\n",
    "\n",
    "The results are retrieved because they talk about regression in that lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor (Andrew Ng) :All right, so who thought driving could be that dramatic, right? \n",
      "Switch back to the chalkboard, please. I s hould say, this work was done about 15 years \n",
      "ago and autonomous driving has come a long way. So many of you will have heard of the \n",
      "DARPA Grand Challenge, where one of my colleagues, Sebastian Thrun, the winning \n",
      "team's drive a car across a desert by itself.  \n",
      "So Alvin was, I think, absolutely amazing wo rk for its time, but autonomous driving has \n",
      "obviously come a long way since then. So what  you just saw was an example, again, of \n",
      "supervised learning, and in particular it was an  example of what they  call the regression \n",
      "problem, because the vehicle is trying to predict a continuous value variables of a \n",
      "continuous value steering directions , we call the regression problem.  \n",
      "And what I want to do today is talk about our first supervised learning algorithm, and it \n",
      "will also be to a regression task. So for the running example that I'm going to use \n",
      "throughout today's lecture, you're going to retu rn to the example of  trying to predict \n",
      "housing prices. So here's actually a data set collected by TA, Dan Ramage, on housing \n",
      "prices in Portland, Oregon.  \n",
      "So here's a dataset of a number of houses of different sizes, and here are their asking \n",
      "prices in thousands of dollars, $200,000. And so we  can take this data and plot it, square \n",
      "feet, best price, and so you make your other dataset like that. And the question is, given a\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of these issues, the storage step and the corresponding similarity search are not enough and we need the retrieval step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Retrieval\n",
    "\n",
    "![Step 4: Retrieval](pics/rag_step_4.png)\n",
    "\n",
    "One of the shortcomings of the similarity search is that sometimes we don't get the most relevant splits that have to do with the question from the user.\n",
    "\n",
    "Retrieval is relevant at *query time* &mdash; you have received a query and you want to end up with the set of most relevant splits regarding the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these sections we will discuss certain techniques that will help us get better results from our vector store.\n",
    "\n",
    "These techniques can be broadly classified as follows:\n",
    "+ Techniques to improve query results obtained from the vector store:\n",
    "    + Maximum Marginal Relevance (MMR) to take into account diversity of results.\n",
    "    + Using metadata in vector store queries\n",
    "\n",
    "+ LLM-aided retrieval\n",
    "    + SelfQuery\n",
    "    + Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving query results with MMR technique\n",
    "\n",
    "Maximum Marginal Relevance (MMR) is a technique that lets you retrieve a set of diverse results from the vector database instead of only the most relevant ones.\n",
    "\n",
    "That is, when using this technique you reduce the possibility that important information is missed when you query the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this technique you:\n",
    "\n",
    "1. Query the vector store to choose the most similar responses (using semantic similarity).\n",
    "2. Amongst those responses, choose the most diverse ones.\n",
    "\n",
    "The following diagram illustrates the idea behind this technique:\n",
    "\n",
    "![MMR](pics/mmr_retrieval_technique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-aided retrieval\n",
    "\n",
    "The following sections will introduce the LLM-aided retrieval techniques so that you can see where those techniques help.\n",
    "\n",
    "Note also that when using the LLM-aided techniques you will be making more calls to the language model, and therefore the cost of the solution will increase. However, these techniques really make all the difference when increase the quality of the overall solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelfQuery\n",
    "\n",
    "With LLM-aided retrieval you run the question through an LLM to be able to split the original question into two separate pieces:\n",
    "+ a filter\n",
    "+ a search term\n",
    "\n",
    "Then, you'd be able to pass the filter to the vector store's metadata engine, and the search term to the vector store's similarity search engine.\n",
    "\n",
    "The following picture illustrates the approach:\n",
    "\n",
    "![LLM-aided retrieval (SelfQuery)](pics/llm-aided-retrieval-selfquery.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression\n",
    "\n",
    "Another LLM-aided retrieval technique is the *Compression*.\n",
    "\n",
    "You will have noticed that when you query the database you will end up with a set of `Document` objects that contain the most relevant information, but that maybe only two or three sentences will be useful to answer the query.\n",
    "\n",
    "the idea behind this technique is to pass the relevant splits retrieved using the basic similarity search, so that only the most relevant segments are to be considered in the final language mode call.\n",
    "\n",
    "The following diagram illustrates this approach:\n",
    "\n",
    "![LLM-aided retrieval (Compression)](pics/llm-aided-retrieval-compression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval techniques in action\n",
    "\n",
    "In this section we will explore how to implement the retrieval techniques using LangChain.\n",
    "\n",
    "Because we have already gone through:\n",
    "+ Step 1: Document loading\n",
    "+ Step 2: Splitting\n",
    "+ Step 3: Storage\n",
    "\n",
    "we can directly instantiate our *embedding function*  that we will use to create the embedding vector of the user's query, and load the contents of the database from the persist directory:\n",
    "\n",
    "Note that we need to unload SQLite3 default version and use a more modern one first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_path = \"./chroma_data/\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"AZURE_OPENAI_TEXT_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then make sure that all of our splits have been successfully retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())\n",
    "assert vectordb._collection.count() == 209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using MMR to get more diverse results\n",
    "\n",
    "To develop our intuition about how MMR technique works, lets load a smaller piece of information into a database with information about mushrooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a small db with the splits from that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that it has been correctly loaded in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert smalldb._collection.count() == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start querying the database and getting some splits using the basic similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents doc[0]: doc.page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'\n",
      "contents doc[1]: doc.page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).'\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\"\n",
    "docs = smalldb.similarity_search(question, k=2)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"contents doc[{i}]: {doc.page_content=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the results coming out of the loaded knowledge base are relevant (they are related to Amanita Phalloides which is a white mushroom with a large fruiting body), they are ignoring the fact that Amanita Phalloides is a poisonous mushroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply now the MMR retrieval technique, which is supposed to improve the quality of the results by including more diverse information, and see if that fact is retrieved:\n",
    "\n",
    "![MMR](pics/mmr_retrieval_technique.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents doc[0]: doc.page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'\n",
      "contents doc[1]: doc.page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.'\n"
     ]
    }
   ],
   "source": [
    "docs = smalldb.max_marginal_relevance_search(\n",
    "    question,\n",
    "    fetch_k=3,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"contents doc[{i}]: {doc.page_content=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how applying MMR technique effectively retrieves better results, reducing duplication and including more diverse details from our knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm it by applying the same approach to our larger example. We will first use the basic similarity search, confirm that some of the information is duplicated, and then apply MMR and see that we get better results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents doc[0]: doc.page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your'\n",
      "contents doc[1]: doc.page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your'\n",
      "contents doc[2]: doc.page_content='into his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.'\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about matlab?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"contents doc[{i}]: {doc.page_content=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results of the similarity search query returns duplicated information in the first two documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our expectation once we apply the MMR technique, is that we will get more diverse deduplicated results:\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| We're using the default `fetch_k` value. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents doc[0]: doc.page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your'\n",
      "contents doc[1]: doc.page_content='algorithm then? So what’s different? How come  I was making all that noise earlier about \\nleast squares regression being a bad idea for classification problems and then I did a \\nbunch of math and I skipped some steps, but I’m, sort of, claiming at the end they’re \\nreally the same learning algorithm?  \\nStudent: [Inaudible] constants?  \\nInstructor (Andrew Ng) :Say that again.  \\nStudent: [Inaudible]  \\nInstructor (Andrew Ng) :Oh, right. Okay, cool.'\n",
      "contents doc[2]: doc.page_content=\"learning algorithms to teach a car how to  drive at reasonably high speeds off roads \\navoiding obstacles.  \\nAnd on the lower right, that's a robot program med by PhD student Eva Roshen to teach a \\nsort of somewhat strangely configured robot how to get on top of an obstacle, how to get \\nover an obstacle. Sorry. I know the video's kind of small. I hope you can sort of see it. \\nOkay?  \\nSo I think all of these are robots that I thi nk are very difficult to hand-code a controller \\nfor by learning these sorts of l earning algorithms. You can in relatively short order get a \\nrobot to do often pretty amazing things.  \\nOkay. So that was most of what I wanted to say today. Just a couple more last things, but \\nlet me just check what questions you have righ t now. So if there are no questions, I'll just \\nclose with two reminders, which are after class today or as you start to talk with other \\npeople in this class, I just encourage you again to start to form project partners, to try to \\nfind project partners to do your project with. And also, this is a good time to start forming \\nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \\nencourage you to try to star t to do both of those today, okay? Form study groups, and try \\nto find two other project partners.  \\nSo thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \\ndays.\"\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.max_marginal_relevance_search(question, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"contents doc[{i}]: {doc.page_content=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the duplication has been removed from the result set when applying the MMR technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the LLM-aided *SelfQuery* technique\n",
    "\n",
    "When using the LLM-aided *SelfQuery* technique, we improve the quality of the result set by running the query through an LLM to split the semantic search piece and the metadata search piece from the user's question:\n",
    "\n",
    "![SelfQuery](pics/llm-aided-retrieval-selfquery.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already saw that by itself, the basic similarity search is not smart enough to differentiate metadata information from semantic info in the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results metadata[0]: doc.metadata={'page': 0, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[1]: doc.metadata={'page': 2, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf'}\n",
      "results metadata[2]: doc.metadata={'page': 14, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"results metadata[{i}]: {doc.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that results from the 2nd lecture has been pulled too, which is not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `similarity_search()` method let us include the metadata portion of the query as a filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results metadata[0]: doc.metadata={'page': 0, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[1]: doc.metadata={'page': 14, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[2]: doc.metadata={'page': 4, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\": \"data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf\"}\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"results metadata[{i}]: {doc.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now all the results come from the third lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using *SelfQuery* we will be able to get the same results, but without having to write the filter ourselves.\n",
    "\n",
    "For this to work, we have to make the language model aware of the nature of the document's metadata. This should be as descriptive as possible.\n",
    "\n",
    "If you inspect the results metadata, you see that we only have two fields: `source` and `page`.\n",
    "\n",
    "As a first step, we will need to create a metadata field descriptor like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture from where the chunk is from, should be one of `data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf`, `data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf`, or `data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that description for the `source` metadata field includes the actual possible values:\n",
    "+ `data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf`\n",
    "+ `data/pdfs/cs229_lectures_MachineLearning-Lecture02.pdf`\n",
    "+ `data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf`\n",
    "\n",
    "Should the location change, the information below should be updated too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to apply the *SelfQuery* technique, which is implemented in LangChain via the `SelfQueryRetriever` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "    model_name=\"gpt-35-turbo-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the retriever in place, we can start interrogating our vector database and see if the retrieved results effectively come from the third lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents retrieved: 4\n",
      "results metadata[0]: doc.metadata={'page': 14, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[1]: doc.metadata={'page': 10, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[2]: doc.metadata={'page': 0, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n",
      "results metadata[3]: doc.metadata={'page': 10, 'source': 'data/pdfs/cs229_lectures_MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "print(f\"Number of documents retrieved: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"results metadata[{i}]: {doc.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It must be noted that only models supporting the *Completions API* will work for *SelfQuery* techniques. In the example below, we've used `\"gpt-35-turbo-instruct\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the LLM-aided *Compression* technique\n",
    "\n",
    "The *Compression* technique, also known as *Contextual Compression*, let us get more focused results by removing extraneous information that might be present in the retrieved chunks.\n",
    "\n",
    "![Compression technique](pics/llm-aided-retrieval-compression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a `ContextualCompressionRetriever` object that simplifies the implementation of this technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import AzureOpenAI\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"chat\",\n",
    "    model_name=\"gpt-35-turbo\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the compression retriever in place, we can ask a question and check that the results are more focused than when doing a basic similarity search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a helper function to print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"{len(docs)} document{'' if len(docs) == 1 else 's'} retrieved\")\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1} (length: {len(d.page_content)}):\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 (length: 1046):\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1046):\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1024):\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "\n",
      "Correct Output: \n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The sun was shining on the sea, Shining with all his might: He did his very best to make The billows smooth and bright-- And this was odd, because it was The middle of the night.  \n",
      "The moon was shining sulkily, Because she thought the sun Had got no business to be there After the day was done-- \"It's very rude of him,\" she said, \"To come and spoil the fun!\"  \n",
      "The sea was wet as wet could be, The sands were dry as dry. You could not see a cloud, because No cloud was in the sky: No birds were flying overhead-- There were no birds to fly.  \n",
      "The Walrus and the Carpenter Were walking close at hand; They wept like anything to see Such quantities of sand: \"If this were only cleared away,\" They said, \"it would be grand!\"  \n",
      "\"If seven maids with seven mops Swept it for half a year. Do you suppose,\" the Walrus said, \"That they could get it clear?\"  \n",
      "\"I doubt it,\" said the Carpenter, And shed a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 1024):\n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "\n",
      "Correct Output: \n",
      "\n",
      "\"Oh, it was the MATLAB.\"\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The sun was shining on the sea, Shining with all his might: He did his very best to make The billows smooth and bright-- And this was odd, because it was The middle of the night.  \n",
      "The moon was shining sulkily, Because she thought the sun Had got no business to be there After the day was done-- \"It's very rude of him,\" she said, \"To come and spoil the fun!\"  \n",
      "The sea was wet as wet could be, The sands were dry as dry. You could not see a cloud, because No cloud was in the sky: No birds were flying overhead-- There were no birds to fly.  \n",
      "The Walrus and the Carpenter Were walking close at hand; They wept like anything to see Such quantities of sand: \"If this were only cleared away,\" They said, \"it would be grand!\"  \n",
      "\"If seven maids with seven mops Swept it for half a year. Do you suppose,\" the Walrus said, \"That they could get it clear?\"  \n",
      "\"I doubt it,\" said the Carpenter, And shed a\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about MATLAB?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the results using the regular similarity search will typically be longer and therefore, less focused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 (length: 1443):\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1443):\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1424):\n",
      "\n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutori al in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical th ing is the discussion s ections. So discussion \n",
      "sections will be taught by the TAs, and atte ndance at discussion sections is optional, \n",
      "although they'll also be recorded and televi sed. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or th ree weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 1424):\n",
      "\n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutori al in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical th ing is the discussion s ections. So discussion \n",
      "sections will be taught by the TAs, and atte ndance at discussion sections is optional, \n",
      "although they'll also be recorded and televi sed. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or th ree weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about MATLAB?\"\n",
    "docs = vectordb.similarity_search(question)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the compressed docs we're getting duplicated results.\n",
    "\n",
    "Nothing prevents us from applying both *Contextual Compression* (to get more focused results) and *MMR* (to reduce duplication and get more diverse results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 (length: 1046):\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1000):\n",
      "\n",
      "- \"And the student said, \"Oh, it was the MATLAB.\"\"\n",
      "- \"So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutori al in one of the discussion sections for those of you that don't know it.\"\n",
      "\n",
      "Answer: \"Oh, it was the MATLAB.\" and \"So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutori al in one of the discussion sections for those of you that don't know it.\"\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The sun was shining on the sea, Shining with all his might: He did his very best to make The billows smooth and bright-- And this was odd, because it was The middle of the night.  \n",
      "The moon was shining sulkily, Because she thought the sun Had got no business to be there After the day was done-- \"It's very rude of him,\" she said, \"To come and spoil the fun!\"  \n",
      "The sea was wet as wet could be, The sands were dry as dry. You could\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1211):\n",
      "\n",
      "'what  you just saw was an example, again, of supervised learning, and in particular it was an  example of what they  call the regression problem, because the vehicle is trying to predict a continuous value variables of a continuous value steering directions , we call the regression problem.  And what I want to do today is talk about our first supervised learning algorithm, and it will also be to a regression task.'\n",
      "\n",
      "Correct output: 'supervised learning, and in particular it was an  example of what they  call the regression problem, because the vehicle is trying to predict a continuous value variables of a continuous value steering directions , we call the regression problem.  And what I want to do today is talk about our first supervised learning algorithm, and it will also be to a regression task.'\n",
      "\n",
      "Test case 2: \n",
      "\n",
      "> Question: What did they say about the weather?\n",
      "> Context:\n",
      ">>>\n",
      "Instructor (Andrew Ng): So, welcome to the first week of the course. This week, we're going to be talking about what is machine learning, and also, we're going to be talking about supervised learning. So, let's get started. \n",
      "So, what is machine learning? Here's Arthur Samuel's definition from 1959. Machine learning is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 1040):\n",
      "\n",
      "```\n",
      "NO_OUTPUT\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The sun is shining and the birds are chirping. The weather is perfect for a picnic. \n",
      ">>>\n",
      "Extracted relevant parts: \n",
      "```\n",
      "NO_OUTPUT\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The quick brown fox jumps over the lazy dog.\n",
      ">>>\n",
      "Extracted relevant parts: \n",
      "```\n",
      "NO_OUTPUT\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog. \n",
      ">>>\n",
      "Extracted relevant parts: \n",
      "```\n",
      "NO_OUTPUT\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "> Question: What is the context about?\n",
      "> Context:\n",
      ">>>\n",
      "The quick brown fox jumps over the lazy dog. The quick\n"
     ]
    }
   ],
   "source": [
    "compression_mmr_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type=\"mmr\")\n",
    ")\n",
    "\n",
    "question = \"What did they say about Matlab?\"\n",
    "\n",
    "compressed_diverse_docs = compression_mmr_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_diverse_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that beyond responses #1 and #2 we're getting strange results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using other classical retrieval techniques\n",
    "\n",
    "All the retrieval techniques we've seen so far are based on techniques implemented on top of vector stores, but LangChain also supports other retrieval techniques that are based on more traditional Natural Language Processing (NLP) and Machine Learning (ML) fields:\n",
    "\n",
    "* SVM retriever\n",
    "* TF-IDF retriever\n",
    "\n",
    "The following snippets illustrate how to use these techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_pages_text = [p.page_content for p in pages]\n",
    "all_text_str = \" \".join(all_pages_text)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "splits = text_splitter.split_text(all_text_str)\n",
    "\n",
    "svm_retriever = SVMRetriever.from_texts(splits, embeddings)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the non-vectorstore based retrievers in place, we can start asking questions.\n",
    "\n",
    "Let's start with the SVM retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents retrieved\n",
      "Document 1 (length: 1435):\n",
      "\n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1490):\n",
      "\n",
      "So as part of forming study groups, later t oday as you get to know your classmates, I \n",
      "definitely also encourage you to grab two ot her people and form a group of up to three \n",
      "people for your project, okay? And just start brainstorming ideas for now amongst \n",
      "yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \n",
      "with us.  \n",
      "Okay. So one more organizational ques tion. I'm curious, how many of you know \n",
      "MATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \n",
      "know Octave or have used Octave ? Oh, okay, much smaller number.  \n",
      "So as part of this class, especially in the homeworks, we'll ask you to implement a few \n",
      "programs, a few machine learning algorithms as  part of the homeworks. And most of  those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1433):\n",
      "\n",
      "Student : [Inaudible] what language [inaudible]?  \n",
      "Instructor (Andrew Ng): So let's see. There is no C programming in this class other \n",
      "than any that you may choose to do yourself in your project. So all the homeworks can be \n",
      "done in MATLAB or Octave, and let's see. A nd I guess the program prerequisites is more \n",
      "the ability to understand big?O notation and know ledge of what a data structure, like a \n",
      "linked list or a queue or bina ry treatments, more so than  your knowledge of C or Java \n",
      "specifically. Yeah?  \n",
      "Student : Looking at the end semester project, I mean, what exactly will you be testing \n",
      "over there? [Inaudible]?  \n",
      "Instructor (Andrew Ng) : Of the project?  \n",
      "Student : Yeah.  \n",
      "Instructor (Andrew Ng) : Yeah, let me answer that later.  In a couple of weeks, I shall \n",
      "give out a handout with guidelines for the pr oject. But for now, we should think of the \n",
      "goal as being to do a cool piec e of machine learning work that  will let you experience the  joys of machine learning firs thand and really try to think about doing a publishable piece \n",
      "of work.  \n",
      "So many students will try to build a cool machine learning application. That's probably \n",
      "the most common project. Some students will try to improve state-of-the-art machine \n",
      "learning. Some of those projects are also very  successful. It's a littl e bit harder to do. And \n",
      "there's also a smaller minority of students th at will sometimes try to prove — develop the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 1460):\n",
      "\n",
      "complicated algorithm, right, to take this overlapping audio streams and separate them \n",
      "out. It sounds like a pretty complicated thi ng to do. So you're gonna ask how complicated \n",
      "is it really to implement an  algorithm like this? It turns out if you do it in MATLAB, you \n",
      "can do it in one line of code.  \n",
      "So I got this from Samuel Wyse at Toront o, U of Toronto, and the example I showed you \n",
      "actually used a more complicated ICA algorithm than this. But nonetheless, I guess this is \n",
      "why for this class I'm going to ask you to  do most of your programming in MATLAB and \n",
      "Octave because if you try to implement the sa me algorithm in C or Java or something, I \n",
      "can tell you from personal, painful experien ce, you end up writing pages and pages of \n",
      "code rather than relatively few lines of code. I'll also mention that it did take researchers \n",
      "many, many years to come up with that one line of code, so this is not easy.  \n",
      "So that was unsupervised learning, and then the last of the four major topics I wanna tell \n",
      "you about is reinforcement learning. And this  refers to problems where you don't do one-\n",
      "shot decision-making. So, for example, in  the supervised learning cancer prediction \n",
      "problem, you have a patient come in, you predict that the cancer is malignant or benign. \n",
      "And then based on your prediction, maybe the pa tient lives or dies, and then that's it, \n",
      "right? So you make a decision and then there's a consequence. You either got it right or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about Matlab?\"\n",
    "\n",
    "docs_svm = svm_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(docs_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, using TF-IDF retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents retrieved\n",
      "Document 1 (length: 1449):\n",
      "\n",
      "Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \n",
      "picture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \n",
      "group the picture into regions. Let me actually blow that up so that you can see it more \n",
      "clearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \n",
      "grouping the image into [inaudible] regions.  \n",
      "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \n",
      "we take this clustering and us e it to build a 3D model of the world? And so using the \n",
      "clustering, they then had a lear ning algorithm try to learn what the 3D structure of the \n",
      "world looks like so that they could come up with a 3D model that you can sort of fly \n",
      "through, okay? Although many people used to th ink it's not possible to take a single \n",
      "image and build a 3D model, but using a lear ning algorithm and that sort of clustering \n",
      "algorithm is the first step. They were able to.  \n",
      "I'll just show you one more example. I like this  because it's a picture of Stanford with our \n",
      "beautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \n",
      "the same sort of unsupervised learning algor ithm, you can group the pixels into different \n",
      "regions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1435):\n",
      "\n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1490):\n",
      "\n",
      "So as part of forming study groups, later t oday as you get to know your classmates, I \n",
      "definitely also encourage you to grab two ot her people and form a group of up to three \n",
      "people for your project, okay? And just start brainstorming ideas for now amongst \n",
      "yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \n",
      "with us.  \n",
      "Okay. So one more organizational ques tion. I'm curious, how many of you know \n",
      "MATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \n",
      "know Octave or have used Octave ? Oh, okay, much smaller number.  \n",
      "So as part of this class, especially in the homeworks, we'll ask you to implement a few \n",
      "programs, a few machine learning algorithms as  part of the homeworks. And most of  those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 1443):\n",
      "\n",
      "materials that I'll be covering in the main  lectures. And attend ance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from l ogistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advi se against it, mainly because in the last \n",
      "problem set, we actually supply some code th at will run in Octave  but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] pr oject [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with  a larger group, you probably — I recommend \n",
      "trying to form a team, but it's actually totally fine to do it in a sma ller group if you want.  \n",
      "Student : [Inaudible] what language [inaudible]?  \n",
      "Instructor (Andrew Ng): So let's see. There is no C programming in this class other\n"
     ]
    }
   ],
   "source": [
    "question = \"What did they say about Matlab?\"\n",
    "\n",
    "docs_tfidf = tfidf_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(docs_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finalizes all the exploration work we've done around \"Step 4: Retrieval\". We've seen several techniques, included LLM-aided ones such as *SelfQueryRetriever*, in which an LLM is used to come up with filters that include nested metadata structures that can be used to effectively filter out the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Output\n",
    "\n",
    "![Step 5: Retrieval](pics/rag_step_5.png)\n",
    "\n",
    "In this final step we take the documents that were retrieved as a result of the previous retrieval step, and the question written by the user, and pass them both to a language model and ask it to craft an answer to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following diagram is an annotated view of the process that identifies the different components:\n",
    "\n",
    "![Question-Answer Detailed Workflow](pics/question_answer_detailed_wf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the default technique is to pass all the splits to the LLM in a single call. In order to do so, we have to make sure that the length of the information we pass to the LLM does not exceed the LLM's context window size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the amount of `Document` objects retrieved can be large, and LLMs context windows are limited, we might find that all the information won't fit in a single call to the language model.\n",
    "\n",
    "Three of the most popular methods to deal with this problem are:\n",
    "\n",
    "1. Map_reduce\n",
    "2. Refine\n",
    "3. Map_rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the default technique for Output (Question-Answering)\n",
    "\n",
    "To use the default technique, in which the whole set of relevant results fit in the model's context window, and therefore can be sent in one shot to the LLM we have to instantiate the LLM telling it that we need it to answer a question.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| The default technique for question-answering is called `\"stuff\"`. |\n",
    "\n",
    "This will require setting an extra parameter `temperature`, which we will set to zero (`temperature=0`), that will help get factual (rather than invented) answers. That is, this parameter controls the variability of the results, and affects the fidelity of the answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=\"chat\",\n",
    "    model=\"gpt-35-turbo\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to instantiate a `RetrievalQA` object to create a chain that first does a retrieval step to fetch relevant documents, then passes those documents into an LLM to generate a response.\n",
    "\n",
    "A chain refers to sequence of calls (whether to an LLM, a tool, or a data processing step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the qa_chain in place, we can invoke it passing the original question from the user in the `\"query\"` field, as shown below. The response will be a dictionary object, with the LLM response available in the `\"result\"` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The major topics for this class are machine learning and its various applications. The course may also cover statistics and algebra as refreshers, and there will be discussion sections to go over extensions of the material covered in the main lectures.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the major topics for this class?\"\n",
    "\n",
    "answer_from_llm = qa_chain({\"query\": question})\n",
    "\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the code above we've demonstrated the first end-to-end flow:\n",
    "1. Document Loading: We identified a few PDFs that we used as our knowledge base.\n",
    "2. Splitting: We created chunks of the documents of a certain size using a text splitter.\n",
    "3. Storage: We created the corresponding embedding vectors for those chunks and store them in a vector store so that we could run a similarity search.\n",
    "4. Retrieval: We got a question from the user, and interrogated the vector store to get a set of relevant splits (that is, a set of splits that have to do with the user's question).\n",
    "5. Output: We sent the relevant splits along with the question to the LLM so that it could craft a proper answer to the user's question.\n",
    "\n",
    "![End-to-End Question-Answer Flow](pics/rag_stages_hl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can see that the chain hid a lot of processing under the hood to simplify the developer's experience.\n",
    "\n",
    "Let's see what are the parameters we can play with to try to influence the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important configuration parameter we can use is the *prompt*.\n",
    "\n",
    "The prompt is the element that takes in the relevant splits, and the user's question and passes it to the language model.\n",
    "\n",
    "Typically, you will define a prompt template which will be passed to the LLM. The prompt template will contain:\n",
    "+ certain instructions about how to use the different pieces of the context. Context is the generic term for the information that results from the *\"Retrieval\"* step. In our case, the context are the relevant splits returned by a similarity search on the vector store when using the user's question as the query.\n",
    "\n",
    "+ a placeholder for the context variable, such as `{context}`.\n",
    "\n",
    "+ the user's question.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"Thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `{context}` placeholder is where the documents will go, and the `{question}` placeholder is where the question will go.\n",
    "\n",
    "With the new prompt in place, we can instantiate a new Question-Answering chain with the same model and vector db, but a tailored prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start getting answers using our tailored prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, probability is assumed to be a prerequisite for the class. The instructor assumes familiarity with basic probability and statistics, and will go over some of the prerequisites in the discussion sections as a refresher course. Thanks for asking!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain({\"query\": question})\n",
    "\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting parameter that we can use is `return_source_documents=True`. As you can imagine, this will make the LLM return a `\"source_documents\"` property with the reference to the documents used to infer the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is assumed to be a prerequisite for the class. The instructor assumes familiarity with basic probability and statistics, and will go over some of the prerequisites in the discussion sections as a refresher course. Thanks for asking!\n",
      "4 documents retrieved\n",
      "Document 1 (length: 1415):\n",
      "\n",
      "of this class will not be very program ming intensive, although we will do some \n",
      "programming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \n",
      "I also assume familiarity with basic proba bility and statistics. So most undergraduate \n",
      "statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \n",
      "assume all of you know what ra ndom variables are, that all of you know what expectation \n",
      "is, what a variance or a random variable is. And in case of some of you, it's been a while \n",
      "since you've seen some of this material. At some of the discussion sections, we'll actually \n",
      "go over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n",
      "I'll say a bit more about that later as well.  \n",
      "Lastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \n",
      "linear algebra courses are more than enough. So if you've taken courses like Math 51, \n",
      "103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \n",
      "gonna assume that all of you know what matrix es and vectors are, that you know how to \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \n",
      "But if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \n",
      "the review sections.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 (length: 1415):\n",
      "\n",
      "of this class will not be very program ming intensive, although we will do some \n",
      "programming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \n",
      "I also assume familiarity with basic proba bility and statistics. So most undergraduate \n",
      "statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \n",
      "assume all of you know what ra ndom variables are, that all of you know what expectation \n",
      "is, what a variance or a random variable is. And in case of some of you, it's been a while \n",
      "since you've seen some of this material. At some of the discussion sections, we'll actually \n",
      "go over some of the prerequisites, sort of as  a refresher course under prerequisite class. \n",
      "I'll say a bit more about that later as well.  \n",
      "Lastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \n",
      "linear algebra courses are more than enough. So if you've taken courses like Math 51, \n",
      "103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \n",
      "gonna assume that all of you know what matrix es and vectors are, that you know how to \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \n",
      "But if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \n",
      "the review sections.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 (length: 1441):\n",
      "\n",
      "Instructor (Andrew Ng) :Yeah, yeah. I mean, you’re asking about overfitting, whether \n",
      "this is a good model. I thi nk let’s – the thing’s you’re mentioning are maybe deeper \n",
      "questions about learning algorithms  that we’ll just come back to later, so don’t really \n",
      "want to get into that right now. Any more questions? Okay.  \n",
      "So this endows linear regression with a proba bilistic interpretati on. I’m actually going to \n",
      "use this probabil – use this, sort of, probabilist ic interpretation in order to derive our next \n",
      "learning algorithm, which will be our first classification algorithm. Okay? So you’ll recall \n",
      "that I said that regression problems are where the variable Y that you’re trying to predict \n",
      "is continuous values. Now I’m actually gonna ta lk about our first cl assification problem, \n",
      "where the value Y you’re trying to predict will be discreet value. You can take on only a \n",
      "small number of discrete values and in th is case I’ll talk about binding classification \n",
      "where Y takes on only two values, right? So you  come up with classi fication problems if \n",
      "you’re trying to do, say, a medical diagnosis and try to decide based on some features that \n",
      "the patient has a disease or does not have a di sease. Or if in the housing example, maybe \n",
      "you’re trying to decide will this house sell in the next six months or not and the answer is \n",
      "either yes or no. It’ll either be  sold in the next six months or it won’t be. Other standing\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 (length: 428):\n",
      "\n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.  \n",
      "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the \n",
      "material that I'm teaching in the main lectur es. So machine learning is a huge field, and \n",
      "there are a few extensions that we really want  to teach but didn't have time in the main \n",
      "lectures for.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain({\"query\": question})\n",
    "\n",
    "print(answer_from_llm[\"result\"])\n",
    "pretty_print_docs(answer_from_llm[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate, this demonstrates the default Output/Question-Answering technique that stuffs all the relevant splits into the prompt and invokes the LLM.\n",
    "\n",
    "This is a good approach because it only involves one call to the language model, which is provided with the whole set of relevant information so that it can generate the proper answer. The drawback is that in many cases, if there's too much information and the LLM context window is small, all the relevant splits may not be able to fit in the context window, and we will be force to use another technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the context size: Using the Map-Reduce technique\n",
    "\n",
    "The size of the prompt when invoking a language model is limited. Because of that, when the amount of relevant information that you encode in the context is large, you will need to apply a technique to make it smaller.\n",
    "\n",
    "One such technique is Map-Reduce. When using this approach, each of the individual documents is first sent to the language model by itself to get an original answer.\n",
    "\n",
    "Then, those answers are composed into a final answer with a final call to the language model.\n",
    "\n",
    "Note that this technique will involve many more calls to the LLM than you would use with the default technique, but you will be able to operate over an arbitrarily large number of documents.\n",
    "\n",
    "![Map-Reduce technique](pics/map_reduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a parameter `chain_type` in its `RetrievalQA` object to apply the Map-Reduce technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There is no clear answer to this question based on the given portion of the document. The document mentions familiarity with basic probability and statistics as a prerequisite for the class, and there is a brief mention of probability in the text, but it is not clear if it is a main topic of the class. The instructor mentions using a probabilistic interpretation to derive a learning algorithm, but does not go into further detail about probability as a topic.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_mr({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are multiple LLM calls (one per relevant split), the performance of this technique is expected to be much slower than the default one.\n",
    "\n",
    "Also, this technique doesn't ensure that you'll get a better answer, because the final answer is *an ensemble* of the individual answers derived from each split, which might not contain the portion of the information the user is looking for.\n",
    "\n",
    "That is the case in the previous answer which is quite verbose and kind of circular in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is entirely possible to use the Map-Reduce technique and a custom prompt.\n",
    "\n",
    "You should start defining your prompt for the *Map* phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"What is the answer to the following question based on the provided context?\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "QUESTION_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can customize the prompt for the *Reduce* phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following individual_relevant_answers to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"Thanks for asking!\" at the end of the answer.\n",
    "{individual_relevant_answers}\n",
    "Question: {question}\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "COMBINE_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "\n",
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\",\n",
    "    chain_type_kwargs={\n",
    "        \"question_prompt\": QA_PROMPT,\n",
    "        \"combine_prompt\": COMBINE_PROMPT,\n",
    "        \"combine_document_variable_name\": \"individual_relevant_answers\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is mentioned in the context that the instructor will use probabilistic interpretation to derive the next learning algorithm, so it is likely that probability will be covered in the class. Thanks for asking!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_mr({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the context size: Using the Refine technique\n",
    "\n",
    "The Refine technique is another approach you can use when all the relevant information resulting from a similarity search won't fit on a single call to the LLM.\n",
    "\n",
    "In this technique, each of the calls after the first one contains the answer resulting from the previous one:\n",
    "\n",
    "![Refine technique](pics/refine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides the `chain_type=\"refine\"` on the `RetrievalQA.from_chain_type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The topic being discussed in the class is machine learning algorithms, specifically linear regression and classification. The instructor mentions that linear regression can be endowed with a probabilistic interpretation, which will be used to derive the next learning algorithm, the first classification algorithm. The instructor explains that classification problems involve predicting a discrete value, such as whether a patient has a disease or not, or whether a house will sell in the next six months or not. The instructor also mentions that the class will cover some statistics and algebra as a refresher in the discussion sections for those who need it. Additionally, the discussion sections will be used to cover extensions for the material that the instructor didn't have time to cover in the main lectures.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_refine({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a better result than the Map-Reduce chain because information is chained sequentially, and there's less chance that relevant information is missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the other techniques, it is possible to customize the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"The original question is as follows:\n",
    "{question}\n",
    "\n",
    "We have provided an existing answer, including sources (just the ones given in the metadata of the documents, don't make up your own sources):\n",
    "{existing_answer}\n",
    "\n",
    "We have the opportunity to refine the existing answer (only if needed) with some more context below:\n",
    "{context_str}\n",
    "\n",
    "Given the new context, add to the original answer to better answer the question. If you do update it, please update the sources as well. If the context isn't useful, print the original answer. The final answer should incorporate information from the original answer and the new context, but don't make use of phrases like 'additional context', 'original answer', 'new context', 'old answer' because we must hide this answer updation process from end users. Always say \"Thanks for asking!\" at the end of the answer.\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_REFINE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\", \"existing_answer\", \"context_str\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\",\n",
    "    chain_type_kwargs={\"refine_prompt\": QA_CHAIN_REFINE_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, probability is a class topic that may involve some programming, mostly in MATLAB or Octave, but will not be very programming intensive. Students are expected to know what random variables, expectation, variance, and matrices and vectors are. If some students need a refresher, there will be review sections available. Most undergraduate statistics and linear algebra courses should provide sufficient background knowledge. The class may also cover probabilistic interpretation in order to derive learning algorithms, including classification algorithms. Classification problems involve predicting a discrete value, such as whether a patient has a disease or not, or whether a house will sell in the next six months or not. Additionally, the class will have discussion sections to go over extensions for the material that the professor is teaching in the main lectures. These extensions will cover some aspects of machine learning that the professor didn't have time to cover in the main lectures. Thanks for asking! \\n\\nSources: \\n- Lecture transcript or notes from the class in question. \\n- Information about undergraduate statistics and linear algebra courses at Stanford University.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_refine({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the context size: Using the Map-Rerank technique\n",
    "\n",
    "The Map-Rerank technique is yet another approach you can use when all the relevant information resulting from a similarity search won't fit on a single call to the LLM.\n",
    "\n",
    "In this technique, each of the relevant chunks are sent to the LLM model and also scored. The answer with the highest score is selected:\n",
    "\n",
    "![Map-Rerank technique](pics/map_rerank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily apply this technique in LangChain using `chain_type=\"map_rerank\"` in the `RetrievalQA.from_chain_type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain_map_rerank = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_rerank\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, probability is assumed to be a prerequisite for the class.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_map_rerank({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the techniques already seen, you can customize the prompt, although it's a bit more contrived that in the other cases as you'll need to manage the scoring capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the scoring functionality.\n",
    "\n",
    "This requires a RegexParser that will be applied to the answer identified by the the `\"answer\"` key and the score identified by the `\"score\"` key.\n",
    "\n",
    "The answer with the highest score is the one that will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.regex import RegexParser\n",
    "\n",
    "output_parser = RegexParser(\n",
    "    regex=r\"(.*?)\\nScore: (\\d*)\",\n",
    "    output_keys=[\"answer\", \"score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define the prompt, which should be sufficiently detailed so that it is clear how the ranking should be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
    "Question: [question here]\n",
    "Helpful Answer: [answer here]\n",
    "Score: [score between 0 and 100]\n",
    "\n",
    "How to determine the score:\n",
    "- Higher is a better answer\n",
    "- Better responds fully to the asked question, with sufficient level of detail\n",
    "- If you do not know the answer based on the context, that should be a score of 0\n",
    "- Don't be overconfident!\n",
    "\n",
    "Example #1\n",
    "\n",
    "Context:\n",
    "---------\n",
    "Apples are red\n",
    "---------\n",
    "Question: what color are apples?\n",
    "Helpful Answer: red\n",
    "Score: 100\n",
    "\n",
    "Example #2\n",
    "\n",
    "Context:\n",
    "---------\n",
    "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
    "---------\n",
    "Question: what type was the car?\n",
    "Helpful Answer: a sports car or an suv\n",
    "Score: 60\n",
    "\n",
    "Example #3\n",
    "\n",
    "Context:\n",
    "---------\n",
    "Pears are either red or orange\n",
    "---------\n",
    "Question: what color are apples?\n",
    "Helpful Answer: This document does not answer the question\n",
    "Score: 0\n",
    "\n",
    "Begin!\n",
    "\n",
    "Context:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "MAP_RERANK_CHAIN_PROMPT = PromptTemplate.from_template(\n",
    "    template,\n",
    "    output_parser=output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_rerank\",\n",
    "    chain_type_kwargs={\"prompt\": MAP_RERANK_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, probability is assumed to be a prerequisite for the class.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain_map_rerank({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a chatbot\n",
    "\n",
    "In the previous section, we've gone through all the steps of the Retrieval Augmented Generation (RAG) and developed some intuition around the different concepts and techniques used in each step.\n",
    "\n",
    "Now, we can start thinking about implementing an application that includes RAG to solve a portion of the solution, for example a chatbot.\n",
    "\n",
    "In this section we will see what else is needed to implement such an application and it will serve you to understand additional challenges you might face, as well as to learn additional techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main characteristic we're missing from a chatbot application is the management of the state.\n",
    "\n",
    "Let's understand what we mean by that by asking a follow-up question to the LLM and checking that it doesn't work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a question, and immediately after ask for a clarification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, probability is a topic in this class. The instructor assumes familiarity with basic probability and statistics, and mentions that most undergraduate statistics classes will be more than enough preparation.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "answer_from_llm = qa_chain({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prerequisites are needed because the class assumes that all students have a basic knowledge of computer science and computer skills and principles. This includes knowledge of big-O notation and other basic concepts. Without this basic knowledge, it may be difficult for students to understand the material covered in the class.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why are those prerequisites needed?\"\n",
    "\n",
    "answer_from_llm = qa_chain({\"query\": question})\n",
    "answer_from_llm[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the answer elaborates on the lecture prerequisites instead of taking into account that we were interested in the prerequisites that had to do with probability.\n",
    "\n",
    "This happens because the chain doesn't have yet the concept of state.\n",
    "\n",
    "The following diagram illustrates what we want to achieve:\n",
    "\n",
    "![chatbot](pics/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making sure we have our vector store correctly configured with our knowledge base and run a basic scenario to see that by default chat history is not taken into account, then we will add memory to it and see that it works.\n",
    "\n",
    "First, we unload the default pysqlite3 version to load the more modern one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we retrieve our knowledge base from the file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_path = \"./chroma_data/\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"AZURE_OPENAI_TEXT_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we check we have the documents loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())\n",
    "assert vectordb._collection.count() == 209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now a run a basic similarity search as a sort of shakedown test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate our `llm` object that will allow us to interact with the underlying LLM.\n",
    "\n",
    "Note that because we're in *chat mode* we use the `AzureChatOpenAI()` function. This will make the model behave like a chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"chat\",\n",
    "    model_name=\"gpt-35-turbo\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can start chatting with the model without taking into account our knowledge base using the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/01-langchain-intro-hLBsKS3Y-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add some memory to it, as depicted in our blueprint for the chatbot:\n",
    "\n",
    "![Chatbot](pics/chatbot.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides a `ConversationBufferMemory` object that can be used to implement our chat history.\n",
    "\n",
    "That object will be in charge of keeping a list of the previous chat messages, and will pass them along with the question to the chatbot every time.\n",
    "\n",
    "The object can be instantiated by passing the `memory_key` that will identify the placeholder in the prompt. We will also set `return_messages=True` to instruct the object to return the history as a list of messages rather than a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our chatbot, we will need to use a different chain from the usual `RetrievalQA` we've been using.\n",
    "\n",
    "The `ConversationalRetrievalChain` will allow us to pass our recently created memory object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ConversationalRetrievalChain` takes the history and the new question and condenses it into a standalone question to pass to the vector store to look up relevant documents.\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is probability a class topic?',\n",
       " 'chat_history': [HumanMessage(content='Is probability a class topic?'),\n",
       "  AIMessage(content='Yes, probability is a topic assumed to be familiar to students in this class. The instructor mentions that familiarity with basic probability and statistics is assumed, and that most undergraduate statistics classes would be sufficient preparation.')],\n",
       " 'answer': 'Yes, probability is a topic assumed to be familiar to students in this class. The instructor mentions that familiarity with basic probability and statistics is assumed, and that most undergraduate statistics classes would be sufficient preparation.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "\n",
    "llm_answer = qa({\"question\": question})\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can ask a follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The reason for requiring familiarity with basic probability and statistics as prerequisites for this class is that the class assumes that students already know what random variables are, what expectation is, what a variance or a random variable is. The class also assumes that students are familiar with basic linear algebra, such as knowing what matrices and vectors are, how to multiply matrices and vectors, and what a matrix inverse is. These concepts are fundamental to understanding the material covered in the class.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why are those prerequisites needed?\"\n",
    "llm_result = qa({\"question\": question})\n",
    "llm_result[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the language model takes into account our previous conversation to generate the answer.\n",
    "\n",
    "The final thing we can do is wrapping everything together into a function to facilitate the different steps to be taken when you want to implement a chatbot that talks to your documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def load_db(file, k=3):\n",
    "    # Load documents from file\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Generate splits\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=150\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Create the embeddings function\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        deployment=os.getenv(\"AZURE_OPENAI_TEXT_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "    )\n",
    "\n",
    "    # Get an in-memory vector db with the existing splits and embedding function\n",
    "    db = DocArrayInMemorySearch.from_documents(splits, embeddings)\n",
    "\n",
    "    # Instantiate the retriever\n",
    "    retriever = db.as_retriever(k=k)\n",
    "\n",
    "\n",
    "    # Instantiate the LLM\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=\"chat\",\n",
    "        model_name=\"gpt-35-turbo\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Return a chatbot chain, with memory managed externally\n",
    "    qa = RetrievalQA.from_llm(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start using it with any custom document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lecture is being given by Andrew Ng.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = load_db(\"data/pdfs/cs229_lectures_MachineLearning-Lecture01.pdf\")\n",
    "\n",
    "question = \"Who is giving the lecture?\"\n",
    "llm_answer = qa({\"query\": question})\n",
    "llm_answer[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01-langchain-intro-hLBsKS3Y-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
